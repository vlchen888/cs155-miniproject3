{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "import numpy as np\n",
    "from Utility import Utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 layer LST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "util = Utility()\n",
    "sonnets = util.get_shakespeare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnetString = []\n",
    "for i in range(len(sonnets)):\n",
    "    sA = sonnets[i+1]\n",
    "    sonnetString.append(\"\")\n",
    "    for k in sA:\n",
    "        for j in k:\n",
    "            sonnetString[-1] += j + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating entire sonnets\n",
    "int_to_char = {0: ' ', 1: \"'\", 2: ',', 3: '-', 4: 'a', 5: 'b', 6: 'c', 7: 'd', 8: 'e', 9: 'f', 10: 'g', 11: 'h', 12: 'i', 13: 'k', 14: 'l', 15: 'm', 16: 'n', 17: 'o', 18: 'p', 19: 'q', 20: 'r', 21: 's', 22: 't', 23: 'u', 24: 'v', 25: 'w', 26: 'y', 27: 'j', 28: 'x', 29: 'z'}\n",
    "char_to_int = {' ': 0, \"'\": 1, ',': 2, '-': 3, 'a': 4, 'b': 5, 'c': 6, 'd': 7, 'e': 8, 'f': 9, 'g': 10, 'h': 11, 'i': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'y': 26, 'j':27, 'x':28, 'z':29}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "dataX = []\n",
    "dataY = []\n",
    "dataX_seq = []\n",
    "for iter in range(len(sonnetString)):\n",
    "    raw_text = sonnetString[iter]\n",
    "    n_chars = len(raw_text)\n",
    "    seq_in = raw_text[0:seq_length]\n",
    "    dataX_seq.append([char_to_int[char] for char in seq_in])\n",
    "    for i in range(0, n_chars - seq_length, 5):\n",
    "        seq_in = raw_text[i:i + seq_length]\n",
    "        seq_out = raw_text[i + seq_length]\n",
    "        dataX.append([char_to_int[char] for char in seq_in])\n",
    "        dataY.append(char_to_int[seq_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(dataX, (len(dataX), seq_length, 1))\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(X.shape[1], X.shape[2]),return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(200))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "adam = keras.optimizers.Adam(lr = 1e-4)\n",
    "#model.load_weights('weights-improvement-33-0.0104.hdf5')\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam)\n",
    "#filename = \"weights-improvement-61-1.4022.hdf5\"\n",
    "#model.load_weights(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "17409/17409 [==============================] - 68s 4ms/step - loss: 2.9359\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.93593, saving model to weights2-improvement-01-2.9359.hdf5\n",
      "Epoch 2/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.8684\n",
      "\n",
      "Epoch 00002: loss improved from 2.93593 to 2.86837, saving model to weights2-improvement-02-2.8684.hdf5\n",
      "Epoch 3/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.8177\n",
      "\n",
      "Epoch 00003: loss improved from 2.86837 to 2.81768, saving model to weights2-improvement-03-2.8177.hdf5\n",
      "Epoch 4/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.7498\n",
      "\n",
      "Epoch 00004: loss improved from 2.81768 to 2.74978, saving model to weights2-improvement-04-2.7498.hdf5\n",
      "Epoch 5/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.7069\n",
      "\n",
      "Epoch 00005: loss improved from 2.74978 to 2.70692, saving model to weights2-improvement-05-2.7069.hdf5\n",
      "Epoch 6/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.6799\n",
      "\n",
      "Epoch 00006: loss improved from 2.70692 to 2.67991, saving model to weights2-improvement-06-2.6799.hdf5\n",
      "Epoch 7/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.6608\n",
      "\n",
      "Epoch 00007: loss improved from 2.67991 to 2.66083, saving model to weights2-improvement-07-2.6608.hdf5\n",
      "Epoch 8/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.6375\n",
      "\n",
      "Epoch 00008: loss improved from 2.66083 to 2.63749, saving model to weights2-improvement-08-2.6375.hdf5\n",
      "Epoch 9/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.6186\n",
      "\n",
      "Epoch 00009: loss improved from 2.63749 to 2.61857, saving model to weights2-improvement-09-2.6186.hdf5\n",
      "Epoch 10/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.6085\n",
      "\n",
      "Epoch 00010: loss improved from 2.61857 to 2.60850, saving model to weights2-improvement-10-2.6085.hdf5\n",
      "Epoch 11/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.5903\n",
      "\n",
      "Epoch 00011: loss improved from 2.60850 to 2.59029, saving model to weights2-improvement-11-2.5903.hdf5\n",
      "Epoch 12/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.5766\n",
      "\n",
      "Epoch 00012: loss improved from 2.59029 to 2.57665, saving model to weights2-improvement-12-2.5766.hdf5\n",
      "Epoch 13/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.5668\n",
      "\n",
      "Epoch 00013: loss improved from 2.57665 to 2.56678, saving model to weights2-improvement-13-2.5668.hdf5\n",
      "Epoch 14/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.5554\n",
      "\n",
      "Epoch 00014: loss improved from 2.56678 to 2.55538, saving model to weights2-improvement-14-2.5554.hdf5\n",
      "Epoch 15/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.5450\n",
      "\n",
      "Epoch 00015: loss improved from 2.55538 to 2.54505, saving model to weights2-improvement-15-2.5450.hdf5\n",
      "Epoch 16/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.5329\n",
      "\n",
      "Epoch 00016: loss improved from 2.54505 to 2.53293, saving model to weights2-improvement-16-2.5329.hdf5\n",
      "Epoch 17/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.5248\n",
      "\n",
      "Epoch 00017: loss improved from 2.53293 to 2.52478, saving model to weights2-improvement-17-2.5248.hdf5\n",
      "Epoch 18/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.5142\n",
      "\n",
      "Epoch 00018: loss improved from 2.52478 to 2.51423, saving model to weights2-improvement-18-2.5142.hdf5\n",
      "Epoch 19/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.5026\n",
      "\n",
      "Epoch 00019: loss improved from 2.51423 to 2.50260, saving model to weights2-improvement-19-2.5026.hdf5\n",
      "Epoch 20/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.4946\n",
      "\n",
      "Epoch 00020: loss improved from 2.50260 to 2.49464, saving model to weights2-improvement-20-2.4946.hdf5\n",
      "Epoch 21/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.4851\n",
      "\n",
      "Epoch 00021: loss improved from 2.49464 to 2.48508, saving model to weights2-improvement-21-2.4851.hdf5\n",
      "Epoch 22/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.4786\n",
      "\n",
      "Epoch 00022: loss improved from 2.48508 to 2.47863, saving model to weights2-improvement-22-2.4786.hdf5\n",
      "Epoch 23/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.4738\n",
      "\n",
      "Epoch 00023: loss improved from 2.47863 to 2.47383, saving model to weights2-improvement-23-2.4738.hdf5\n",
      "Epoch 24/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.4605\n",
      "\n",
      "Epoch 00024: loss improved from 2.47383 to 2.46053, saving model to weights2-improvement-24-2.4605.hdf5\n",
      "Epoch 25/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.4535\n",
      "\n",
      "Epoch 00025: loss improved from 2.46053 to 2.45350, saving model to weights2-improvement-25-2.4535.hdf5\n",
      "Epoch 26/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.4475\n",
      "\n",
      "Epoch 00026: loss improved from 2.45350 to 2.44752, saving model to weights2-improvement-26-2.4475.hdf5\n",
      "Epoch 27/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.4383\n",
      "\n",
      "Epoch 00027: loss improved from 2.44752 to 2.43831, saving model to weights2-improvement-27-2.4383.hdf5\n",
      "Epoch 28/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.4285\n",
      "\n",
      "Epoch 00028: loss improved from 2.43831 to 2.42848, saving model to weights2-improvement-28-2.4285.hdf5\n",
      "Epoch 29/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.4258\n",
      "\n",
      "Epoch 00029: loss improved from 2.42848 to 2.42576, saving model to weights2-improvement-29-2.4258.hdf5\n",
      "Epoch 30/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.4169\n",
      "\n",
      "Epoch 00030: loss improved from 2.42576 to 2.41688, saving model to weights2-improvement-30-2.4169.hdf5\n",
      "Epoch 31/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.4106\n",
      "\n",
      "Epoch 00031: loss improved from 2.41688 to 2.41056, saving model to weights2-improvement-31-2.4106.hdf5\n",
      "Epoch 32/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.3995\n",
      "\n",
      "Epoch 00032: loss improved from 2.41056 to 2.39951, saving model to weights2-improvement-32-2.3995.hdf5\n",
      "Epoch 33/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.3924\n",
      "\n",
      "Epoch 00033: loss improved from 2.39951 to 2.39241, saving model to weights2-improvement-33-2.3924.hdf5\n",
      "Epoch 34/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.3887\n",
      "\n",
      "Epoch 00034: loss improved from 2.39241 to 2.38869, saving model to weights2-improvement-34-2.3887.hdf5\n",
      "Epoch 35/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.3765\n",
      "\n",
      "Epoch 00035: loss improved from 2.38869 to 2.37652, saving model to weights2-improvement-35-2.3765.hdf5\n",
      "Epoch 36/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.3698\n",
      "\n",
      "Epoch 00036: loss improved from 2.37652 to 2.36983, saving model to weights2-improvement-36-2.3698.hdf5\n",
      "Epoch 37/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.3602\n",
      "\n",
      "Epoch 00037: loss improved from 2.36983 to 2.36020, saving model to weights2-improvement-37-2.3602.hdf5\n",
      "Epoch 38/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.3545\n",
      "\n",
      "Epoch 00038: loss improved from 2.36020 to 2.35452, saving model to weights2-improvement-38-2.3545.hdf5\n",
      "Epoch 39/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.3476\n",
      "\n",
      "Epoch 00039: loss improved from 2.35452 to 2.34755, saving model to weights2-improvement-39-2.3476.hdf5\n",
      "Epoch 40/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.3400\n",
      "\n",
      "Epoch 00040: loss improved from 2.34755 to 2.33999, saving model to weights2-improvement-40-2.3400.hdf5\n",
      "Epoch 41/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.3315\n",
      "\n",
      "Epoch 00041: loss improved from 2.33999 to 2.33153, saving model to weights2-improvement-41-2.3315.hdf5\n",
      "Epoch 42/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.3233\n",
      "\n",
      "Epoch 00042: loss improved from 2.33153 to 2.32329, saving model to weights2-improvement-42-2.3233.hdf5\n",
      "Epoch 43/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.3174\n",
      "\n",
      "Epoch 00043: loss improved from 2.32329 to 2.31743, saving model to weights2-improvement-43-2.3174.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.3121\n",
      "\n",
      "Epoch 00044: loss improved from 2.31743 to 2.31214, saving model to weights2-improvement-44-2.3121.hdf5\n",
      "Epoch 45/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.3024\n",
      "\n",
      "Epoch 00045: loss improved from 2.31214 to 2.30243, saving model to weights2-improvement-45-2.3024.hdf5\n",
      "Epoch 46/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.2949\n",
      "\n",
      "Epoch 00046: loss improved from 2.30243 to 2.29488, saving model to weights2-improvement-46-2.2949.hdf5\n",
      "Epoch 47/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.2884\n",
      "\n",
      "Epoch 00047: loss improved from 2.29488 to 2.28842, saving model to weights2-improvement-47-2.2884.hdf5\n",
      "Epoch 48/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.2834\n",
      "\n",
      "Epoch 00048: loss improved from 2.28842 to 2.28337, saving model to weights2-improvement-48-2.2834.hdf5\n",
      "Epoch 49/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.2714\n",
      "\n",
      "Epoch 00049: loss improved from 2.28337 to 2.27139, saving model to weights2-improvement-49-2.2714.hdf5\n",
      "Epoch 50/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.2686\n",
      "\n",
      "Epoch 00050: loss improved from 2.27139 to 2.26856, saving model to weights2-improvement-50-2.2686.hdf5\n",
      "Epoch 51/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.2590\n",
      "\n",
      "Epoch 00051: loss improved from 2.26856 to 2.25897, saving model to weights2-improvement-51-2.2590.hdf5\n",
      "Epoch 52/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.2511\n",
      "\n",
      "Epoch 00052: loss improved from 2.25897 to 2.25106, saving model to weights2-improvement-52-2.2511.hdf5\n",
      "Epoch 53/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.2436\n",
      "\n",
      "Epoch 00053: loss improved from 2.25106 to 2.24364, saving model to weights2-improvement-53-2.2436.hdf5\n",
      "Epoch 54/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.2419\n",
      "\n",
      "Epoch 00054: loss improved from 2.24364 to 2.24192, saving model to weights2-improvement-54-2.2419.hdf5\n",
      "Epoch 55/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.2325\n",
      "\n",
      "Epoch 00055: loss improved from 2.24192 to 2.23250, saving model to weights2-improvement-55-2.2325.hdf5\n",
      "Epoch 56/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.2231\n",
      "\n",
      "Epoch 00056: loss improved from 2.23250 to 2.22312, saving model to weights2-improvement-56-2.2231.hdf5\n",
      "Epoch 57/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.2205\n",
      "\n",
      "Epoch 00057: loss improved from 2.22312 to 2.22050, saving model to weights2-improvement-57-2.2205.hdf5\n",
      "Epoch 58/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.2096\n",
      "\n",
      "Epoch 00058: loss improved from 2.22050 to 2.20957, saving model to weights2-improvement-58-2.2096.hdf5\n",
      "Epoch 59/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.2029\n",
      "\n",
      "Epoch 00059: loss improved from 2.20957 to 2.20287, saving model to weights2-improvement-59-2.2029.hdf5\n",
      "Epoch 60/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.1971\n",
      "\n",
      "Epoch 00060: loss improved from 2.20287 to 2.19707, saving model to weights2-improvement-60-2.1971.hdf5\n",
      "Epoch 61/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.1899\n",
      "\n",
      "Epoch 00061: loss improved from 2.19707 to 2.18995, saving model to weights2-improvement-61-2.1899.hdf5\n",
      "Epoch 62/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.1841\n",
      "\n",
      "Epoch 00062: loss improved from 2.18995 to 2.18407, saving model to weights2-improvement-62-2.1841.hdf5\n",
      "Epoch 63/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.1748\n",
      "\n",
      "Epoch 00063: loss improved from 2.18407 to 2.17481, saving model to weights2-improvement-63-2.1748.hdf5\n",
      "Epoch 64/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.1646\n",
      "\n",
      "Epoch 00064: loss improved from 2.17481 to 2.16455, saving model to weights2-improvement-64-2.1646.hdf5\n",
      "Epoch 65/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.1636\n",
      "\n",
      "Epoch 00065: loss improved from 2.16455 to 2.16361, saving model to weights2-improvement-65-2.1636.hdf5\n",
      "Epoch 66/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.1565\n",
      "\n",
      "Epoch 00066: loss improved from 2.16361 to 2.15646, saving model to weights2-improvement-66-2.1565.hdf5\n",
      "Epoch 67/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.1492\n",
      "\n",
      "Epoch 00067: loss improved from 2.15646 to 2.14920, saving model to weights2-improvement-67-2.1492.hdf5\n",
      "Epoch 68/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.1422\n",
      "\n",
      "Epoch 00068: loss improved from 2.14920 to 2.14216, saving model to weights2-improvement-68-2.1422.hdf5\n",
      "Epoch 69/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.1356\n",
      "\n",
      "Epoch 00069: loss improved from 2.14216 to 2.13562, saving model to weights2-improvement-69-2.1356.hdf5\n",
      "Epoch 70/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.1285\n",
      "\n",
      "Epoch 00070: loss improved from 2.13562 to 2.12847, saving model to weights2-improvement-70-2.1285.hdf5\n",
      "Epoch 71/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.1232\n",
      "\n",
      "Epoch 00071: loss improved from 2.12847 to 2.12322, saving model to weights2-improvement-71-2.1232.hdf5\n",
      "Epoch 72/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.1150\n",
      "\n",
      "Epoch 00072: loss improved from 2.12322 to 2.11504, saving model to weights2-improvement-72-2.1150.hdf5\n",
      "Epoch 73/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.1084\n",
      "\n",
      "Epoch 00073: loss improved from 2.11504 to 2.10836, saving model to weights2-improvement-73-2.1084.hdf5\n",
      "Epoch 74/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.0985\n",
      "\n",
      "Epoch 00074: loss improved from 2.10836 to 2.09845, saving model to weights2-improvement-74-2.0985.hdf5\n",
      "Epoch 75/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.0965\n",
      "\n",
      "Epoch 00075: loss improved from 2.09845 to 2.09654, saving model to weights2-improvement-75-2.0965.hdf5\n",
      "Epoch 76/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.0944\n",
      "\n",
      "Epoch 00076: loss improved from 2.09654 to 2.09436, saving model to weights2-improvement-76-2.0944.hdf5\n",
      "Epoch 77/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.0825\n",
      "\n",
      "Epoch 00077: loss improved from 2.09436 to 2.08247, saving model to weights2-improvement-77-2.0825.hdf5\n",
      "Epoch 78/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.0774\n",
      "\n",
      "Epoch 00078: loss improved from 2.08247 to 2.07738, saving model to weights2-improvement-78-2.0774.hdf5\n",
      "Epoch 79/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.0668\n",
      "\n",
      "Epoch 00079: loss improved from 2.07738 to 2.06680, saving model to weights2-improvement-79-2.0668.hdf5\n",
      "Epoch 80/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.0633\n",
      "\n",
      "Epoch 00080: loss improved from 2.06680 to 2.06331, saving model to weights2-improvement-80-2.0633.hdf5\n",
      "Epoch 81/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.0548\n",
      "\n",
      "Epoch 00081: loss improved from 2.06331 to 2.05483, saving model to weights2-improvement-81-2.0548.hdf5\n",
      "Epoch 82/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.0453\n",
      "\n",
      "Epoch 00082: loss improved from 2.05483 to 2.04530, saving model to weights2-improvement-82-2.0453.hdf5\n",
      "Epoch 83/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.0397\n",
      "\n",
      "Epoch 00083: loss improved from 2.04530 to 2.03971, saving model to weights2-improvement-83-2.0397.hdf5\n",
      "Epoch 84/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.0331\n",
      "\n",
      "Epoch 00084: loss improved from 2.03971 to 2.03306, saving model to weights2-improvement-84-2.0331.hdf5\n",
      "Epoch 85/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.0220\n",
      "\n",
      "Epoch 00085: loss improved from 2.03306 to 2.02196, saving model to weights2-improvement-85-2.0220.hdf5\n",
      "Epoch 86/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.0193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00086: loss improved from 2.02196 to 2.01934, saving model to weights2-improvement-86-2.0193.hdf5\n",
      "Epoch 87/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.0101\n",
      "\n",
      "Epoch 00087: loss improved from 2.01934 to 2.01009, saving model to weights2-improvement-87-2.0101.hdf5\n",
      "Epoch 88/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 2.0084\n",
      "\n",
      "Epoch 00088: loss improved from 2.01009 to 2.00837, saving model to weights2-improvement-88-2.0084.hdf5\n",
      "Epoch 89/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.9938\n",
      "\n",
      "Epoch 00089: loss improved from 2.00837 to 1.99381, saving model to weights2-improvement-89-1.9938.hdf5\n",
      "Epoch 90/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.9886\n",
      "\n",
      "Epoch 00090: loss improved from 1.99381 to 1.98859, saving model to weights2-improvement-90-1.9886.hdf5\n",
      "Epoch 91/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.9792\n",
      "\n",
      "Epoch 00091: loss improved from 1.98859 to 1.97918, saving model to weights2-improvement-91-1.9792.hdf5\n",
      "Epoch 92/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.9767\n",
      "\n",
      "Epoch 00092: loss improved from 1.97918 to 1.97675, saving model to weights2-improvement-92-1.9767.hdf5\n",
      "Epoch 93/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.9724\n",
      "\n",
      "Epoch 00093: loss improved from 1.97675 to 1.97241, saving model to weights2-improvement-93-1.9724.hdf5\n",
      "Epoch 94/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.9656\n",
      "\n",
      "Epoch 00094: loss improved from 1.97241 to 1.96557, saving model to weights2-improvement-94-1.9656.hdf5\n",
      "Epoch 95/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.9545\n",
      "\n",
      "Epoch 00095: loss improved from 1.96557 to 1.95453, saving model to weights2-improvement-95-1.9545.hdf5\n",
      "Epoch 96/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.9471\n",
      "\n",
      "Epoch 00096: loss improved from 1.95453 to 1.94705, saving model to weights2-improvement-96-1.9471.hdf5\n",
      "Epoch 97/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.9392\n",
      "\n",
      "Epoch 00097: loss improved from 1.94705 to 1.93924, saving model to weights2-improvement-97-1.9392.hdf5\n",
      "Epoch 98/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.9268\n",
      "\n",
      "Epoch 00098: loss improved from 1.93924 to 1.92681, saving model to weights2-improvement-98-1.9268.hdf5\n",
      "Epoch 99/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.9219\n",
      "\n",
      "Epoch 00099: loss improved from 1.92681 to 1.92193, saving model to weights2-improvement-99-1.9219.hdf5\n",
      "Epoch 100/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.9103\n",
      "\n",
      "Epoch 00100: loss improved from 1.92193 to 1.91028, saving model to weights2-improvement-100-1.9103.hdf5\n",
      "Epoch 101/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.9096\n",
      "\n",
      "Epoch 00101: loss improved from 1.91028 to 1.90963, saving model to weights2-improvement-101-1.9096.hdf5\n",
      "Epoch 102/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.9047\n",
      "\n",
      "Epoch 00102: loss improved from 1.90963 to 1.90473, saving model to weights2-improvement-102-1.9047.hdf5\n",
      "Epoch 103/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.8954\n",
      "\n",
      "Epoch 00103: loss improved from 1.90473 to 1.89536, saving model to weights2-improvement-103-1.8954.hdf5\n",
      "Epoch 104/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.8857\n",
      "\n",
      "Epoch 00104: loss improved from 1.89536 to 1.88567, saving model to weights2-improvement-104-1.8857.hdf5\n",
      "Epoch 105/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.8728\n",
      "\n",
      "Epoch 00105: loss improved from 1.88567 to 1.87285, saving model to weights2-improvement-105-1.8728.hdf5\n",
      "Epoch 106/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.8616\n",
      "\n",
      "Epoch 00106: loss improved from 1.87285 to 1.86163, saving model to weights2-improvement-106-1.8616.hdf5\n",
      "Epoch 107/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.8580\n",
      "\n",
      "Epoch 00107: loss improved from 1.86163 to 1.85797, saving model to weights2-improvement-107-1.8580.hdf5\n",
      "Epoch 108/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.8551\n",
      "\n",
      "Epoch 00108: loss improved from 1.85797 to 1.85506, saving model to weights2-improvement-108-1.8551.hdf5\n",
      "Epoch 109/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.8461\n",
      "\n",
      "Epoch 00109: loss improved from 1.85506 to 1.84613, saving model to weights2-improvement-109-1.8461.hdf5\n",
      "Epoch 110/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.8287\n",
      "\n",
      "Epoch 00110: loss improved from 1.84613 to 1.82873, saving model to weights2-improvement-110-1.8287.hdf5\n",
      "Epoch 111/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.8231\n",
      "\n",
      "Epoch 00111: loss improved from 1.82873 to 1.82308, saving model to weights2-improvement-111-1.8231.hdf5\n",
      "Epoch 112/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.8160\n",
      "\n",
      "Epoch 00112: loss improved from 1.82308 to 1.81600, saving model to weights2-improvement-112-1.8160.hdf5\n",
      "Epoch 113/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.8105\n",
      "\n",
      "Epoch 00113: loss improved from 1.81600 to 1.81051, saving model to weights2-improvement-113-1.8105.hdf5\n",
      "Epoch 114/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.8023\n",
      "\n",
      "Epoch 00114: loss improved from 1.81051 to 1.80233, saving model to weights2-improvement-114-1.8023.hdf5\n",
      "Epoch 115/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.7918\n",
      "\n",
      "Epoch 00115: loss improved from 1.80233 to 1.79175, saving model to weights2-improvement-115-1.7918.hdf5\n",
      "Epoch 116/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.7843\n",
      "\n",
      "Epoch 00116: loss improved from 1.79175 to 1.78431, saving model to weights2-improvement-116-1.7843.hdf5\n",
      "Epoch 117/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.7751\n",
      "\n",
      "Epoch 00117: loss improved from 1.78431 to 1.77511, saving model to weights2-improvement-117-1.7751.hdf5\n",
      "Epoch 118/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.7671\n",
      "\n",
      "Epoch 00118: loss improved from 1.77511 to 1.76705, saving model to weights2-improvement-118-1.7671.hdf5\n",
      "Epoch 119/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.7508\n",
      "\n",
      "Epoch 00119: loss improved from 1.76705 to 1.75083, saving model to weights2-improvement-119-1.7508.hdf5\n",
      "Epoch 120/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.7512\n",
      "\n",
      "Epoch 00120: loss did not improve\n",
      "Epoch 121/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.7387\n",
      "\n",
      "Epoch 00121: loss improved from 1.75083 to 1.73872, saving model to weights2-improvement-121-1.7387.hdf5\n",
      "Epoch 122/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.7261\n",
      "\n",
      "Epoch 00122: loss improved from 1.73872 to 1.72614, saving model to weights2-improvement-122-1.7261.hdf5\n",
      "Epoch 123/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.7191\n",
      "\n",
      "Epoch 00123: loss improved from 1.72614 to 1.71912, saving model to weights2-improvement-123-1.7191.hdf5\n",
      "Epoch 124/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.7063\n",
      "\n",
      "Epoch 00124: loss improved from 1.71912 to 1.70633, saving model to weights2-improvement-124-1.7063.hdf5\n",
      "Epoch 125/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.6982\n",
      "\n",
      "Epoch 00125: loss improved from 1.70633 to 1.69824, saving model to weights2-improvement-125-1.6982.hdf5\n",
      "Epoch 126/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.7007\n",
      "\n",
      "Epoch 00126: loss did not improve\n",
      "Epoch 127/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.6792\n",
      "\n",
      "Epoch 00127: loss improved from 1.69824 to 1.67918, saving model to weights2-improvement-127-1.6792.hdf5\n",
      "Epoch 128/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.6783\n",
      "\n",
      "Epoch 00128: loss improved from 1.67918 to 1.67831, saving model to weights2-improvement-128-1.6783.hdf5\n",
      "Epoch 129/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.6637\n",
      "\n",
      "Epoch 00129: loss improved from 1.67831 to 1.66371, saving model to weights2-improvement-129-1.6637.hdf5\n",
      "Epoch 130/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.6545\n",
      "\n",
      "Epoch 00130: loss improved from 1.66371 to 1.65450, saving model to weights2-improvement-130-1.6545.hdf5\n",
      "Epoch 131/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.6451\n",
      "\n",
      "Epoch 00131: loss improved from 1.65450 to 1.64515, saving model to weights2-improvement-131-1.6451.hdf5\n",
      "Epoch 132/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.6353\n",
      "\n",
      "Epoch 00132: loss improved from 1.64515 to 1.63531, saving model to weights2-improvement-132-1.6353.hdf5\n",
      "Epoch 133/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.6188\n",
      "\n",
      "Epoch 00133: loss improved from 1.63531 to 1.61876, saving model to weights2-improvement-133-1.6188.hdf5\n",
      "Epoch 134/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.6201\n",
      "\n",
      "Epoch 00134: loss did not improve\n",
      "Epoch 135/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.6028\n",
      "\n",
      "Epoch 00135: loss improved from 1.61876 to 1.60285, saving model to weights2-improvement-135-1.6028.hdf5\n",
      "Epoch 136/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.6018\n",
      "\n",
      "Epoch 00136: loss improved from 1.60285 to 1.60178, saving model to weights2-improvement-136-1.6018.hdf5\n",
      "Epoch 137/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.5840\n",
      "\n",
      "Epoch 00137: loss improved from 1.60178 to 1.58401, saving model to weights2-improvement-137-1.5840.hdf5\n",
      "Epoch 138/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.5738\n",
      "\n",
      "Epoch 00138: loss improved from 1.58401 to 1.57381, saving model to weights2-improvement-138-1.5738.hdf5\n",
      "Epoch 139/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.5688\n",
      "\n",
      "Epoch 00139: loss improved from 1.57381 to 1.56880, saving model to weights2-improvement-139-1.5688.hdf5\n",
      "Epoch 140/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.5513\n",
      "\n",
      "Epoch 00140: loss improved from 1.56880 to 1.55126, saving model to weights2-improvement-140-1.5513.hdf5\n",
      "Epoch 141/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.5446\n",
      "\n",
      "Epoch 00141: loss improved from 1.55126 to 1.54461, saving model to weights2-improvement-141-1.5446.hdf5\n",
      "Epoch 142/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.5375\n",
      "\n",
      "Epoch 00142: loss improved from 1.54461 to 1.53746, saving model to weights2-improvement-142-1.5375.hdf5\n",
      "Epoch 143/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.5248\n",
      "\n",
      "Epoch 00143: loss improved from 1.53746 to 1.52479, saving model to weights2-improvement-143-1.5248.hdf5\n",
      "Epoch 144/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.5136\n",
      "\n",
      "Epoch 00144: loss improved from 1.52479 to 1.51360, saving model to weights2-improvement-144-1.5136.hdf5\n",
      "Epoch 145/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.5087\n",
      "\n",
      "Epoch 00145: loss improved from 1.51360 to 1.50873, saving model to weights2-improvement-145-1.5087.hdf5\n",
      "Epoch 146/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.4964\n",
      "\n",
      "Epoch 00146: loss improved from 1.50873 to 1.49636, saving model to weights2-improvement-146-1.4964.hdf5\n",
      "Epoch 147/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.4839\n",
      "\n",
      "Epoch 00147: loss improved from 1.49636 to 1.48392, saving model to weights2-improvement-147-1.4839.hdf5\n",
      "Epoch 148/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.4715\n",
      "\n",
      "Epoch 00148: loss improved from 1.48392 to 1.47152, saving model to weights2-improvement-148-1.4715.hdf5\n",
      "Epoch 149/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.4686\n",
      "\n",
      "Epoch 00149: loss improved from 1.47152 to 1.46862, saving model to weights2-improvement-149-1.4686.hdf5\n",
      "Epoch 150/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.4558\n",
      "\n",
      "Epoch 00150: loss improved from 1.46862 to 1.45577, saving model to weights2-improvement-150-1.4558.hdf5\n",
      "Epoch 151/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.4404\n",
      "\n",
      "Epoch 00151: loss improved from 1.45577 to 1.44038, saving model to weights2-improvement-151-1.4404.hdf5\n",
      "Epoch 152/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.4343\n",
      "\n",
      "Epoch 00152: loss improved from 1.44038 to 1.43433, saving model to weights2-improvement-152-1.4343.hdf5\n",
      "Epoch 153/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.4303\n",
      "\n",
      "Epoch 00153: loss improved from 1.43433 to 1.43032, saving model to weights2-improvement-153-1.4303.hdf5\n",
      "Epoch 154/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.4202\n",
      "\n",
      "Epoch 00154: loss improved from 1.43032 to 1.42016, saving model to weights2-improvement-154-1.4202.hdf5\n",
      "Epoch 155/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.4077\n",
      "\n",
      "Epoch 00155: loss improved from 1.42016 to 1.40772, saving model to weights2-improvement-155-1.4077.hdf5\n",
      "Epoch 156/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.3997\n",
      "\n",
      "Epoch 00156: loss improved from 1.40772 to 1.39974, saving model to weights2-improvement-156-1.3997.hdf5\n",
      "Epoch 157/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.3834\n",
      "\n",
      "Epoch 00157: loss improved from 1.39974 to 1.38337, saving model to weights2-improvement-157-1.3834.hdf5\n",
      "Epoch 158/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.3793\n",
      "\n",
      "Epoch 00158: loss improved from 1.38337 to 1.37928, saving model to weights2-improvement-158-1.3793.hdf5\n",
      "Epoch 159/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.3597\n",
      "\n",
      "Epoch 00159: loss improved from 1.37928 to 1.35973, saving model to weights2-improvement-159-1.3597.hdf5\n",
      "Epoch 160/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.3528\n",
      "\n",
      "Epoch 00160: loss improved from 1.35973 to 1.35278, saving model to weights2-improvement-160-1.3528.hdf5\n",
      "Epoch 161/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.3447\n",
      "\n",
      "Epoch 00161: loss improved from 1.35278 to 1.34466, saving model to weights2-improvement-161-1.3447.hdf5\n",
      "Epoch 162/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.3338\n",
      "\n",
      "Epoch 00162: loss improved from 1.34466 to 1.33380, saving model to weights2-improvement-162-1.3338.hdf5\n",
      "Epoch 163/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.3195\n",
      "\n",
      "Epoch 00163: loss improved from 1.33380 to 1.31955, saving model to weights2-improvement-163-1.3195.hdf5\n",
      "Epoch 164/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.3139\n",
      "\n",
      "Epoch 00164: loss improved from 1.31955 to 1.31391, saving model to weights2-improvement-164-1.3139.hdf5\n",
      "Epoch 165/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.3044\n",
      "\n",
      "Epoch 00165: loss improved from 1.31391 to 1.30438, saving model to weights2-improvement-165-1.3044.hdf5\n",
      "Epoch 166/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.2973\n",
      "\n",
      "Epoch 00166: loss improved from 1.30438 to 1.29728, saving model to weights2-improvement-166-1.2973.hdf5\n",
      "Epoch 167/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.2797\n",
      "\n",
      "Epoch 00167: loss improved from 1.29728 to 1.27966, saving model to weights2-improvement-167-1.2797.hdf5\n",
      "Epoch 168/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.2662\n",
      "\n",
      "Epoch 00168: loss improved from 1.27966 to 1.26618, saving model to weights2-improvement-168-1.2662.hdf5\n",
      "Epoch 169/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.2632\n",
      "\n",
      "Epoch 00169: loss improved from 1.26618 to 1.26316, saving model to weights2-improvement-169-1.2632.hdf5\n",
      "Epoch 170/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.2542\n",
      "\n",
      "Epoch 00170: loss improved from 1.26316 to 1.25424, saving model to weights2-improvement-170-1.2542.hdf5\n",
      "Epoch 171/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.2363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00171: loss improved from 1.25424 to 1.23633, saving model to weights2-improvement-171-1.2363.hdf5\n",
      "Epoch 172/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.2301\n",
      "\n",
      "Epoch 00172: loss improved from 1.23633 to 1.23015, saving model to weights2-improvement-172-1.2301.hdf5\n",
      "Epoch 173/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.2222\n",
      "\n",
      "Epoch 00173: loss improved from 1.23015 to 1.22221, saving model to weights2-improvement-173-1.2222.hdf5\n",
      "Epoch 174/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.2110\n",
      "\n",
      "Epoch 00174: loss improved from 1.22221 to 1.21097, saving model to weights2-improvement-174-1.2110.hdf5\n",
      "Epoch 175/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.2068\n",
      "\n",
      "Epoch 00175: loss improved from 1.21097 to 1.20678, saving model to weights2-improvement-175-1.2068.hdf5\n",
      "Epoch 176/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.1937\n",
      "\n",
      "Epoch 00176: loss improved from 1.20678 to 1.19370, saving model to weights2-improvement-176-1.1937.hdf5\n",
      "Epoch 177/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.1854\n",
      "\n",
      "Epoch 00177: loss improved from 1.19370 to 1.18545, saving model to weights2-improvement-177-1.1854.hdf5\n",
      "Epoch 178/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.1757\n",
      "\n",
      "Epoch 00178: loss improved from 1.18545 to 1.17573, saving model to weights2-improvement-178-1.1757.hdf5\n",
      "Epoch 179/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.1685\n",
      "\n",
      "Epoch 00179: loss improved from 1.17573 to 1.16849, saving model to weights2-improvement-179-1.1685.hdf5\n",
      "Epoch 180/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.1517\n",
      "\n",
      "Epoch 00180: loss improved from 1.16849 to 1.15165, saving model to weights2-improvement-180-1.1517.hdf5\n",
      "Epoch 181/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.1474\n",
      "\n",
      "Epoch 00181: loss improved from 1.15165 to 1.14737, saving model to weights2-improvement-181-1.1474.hdf5\n",
      "Epoch 182/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.1335\n",
      "\n",
      "Epoch 00182: loss improved from 1.14737 to 1.13349, saving model to weights2-improvement-182-1.1335.hdf5\n",
      "Epoch 183/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.1257\n",
      "\n",
      "Epoch 00183: loss improved from 1.13349 to 1.12572, saving model to weights2-improvement-183-1.1257.hdf5\n",
      "Epoch 184/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.1163\n",
      "\n",
      "Epoch 00184: loss improved from 1.12572 to 1.11631, saving model to weights2-improvement-184-1.1163.hdf5\n",
      "Epoch 185/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.1110\n",
      "\n",
      "Epoch 00185: loss improved from 1.11631 to 1.11096, saving model to weights2-improvement-185-1.1110.hdf5\n",
      "Epoch 186/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.1012\n",
      "\n",
      "Epoch 00186: loss improved from 1.11096 to 1.10117, saving model to weights2-improvement-186-1.1012.hdf5\n",
      "Epoch 187/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.0850\n",
      "\n",
      "Epoch 00187: loss improved from 1.10117 to 1.08499, saving model to weights2-improvement-187-1.0850.hdf5\n",
      "Epoch 188/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.0832\n",
      "\n",
      "Epoch 00188: loss improved from 1.08499 to 1.08318, saving model to weights2-improvement-188-1.0832.hdf5\n",
      "Epoch 189/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.0658\n",
      "\n",
      "Epoch 00189: loss improved from 1.08318 to 1.06580, saving model to weights2-improvement-189-1.0658.hdf5\n",
      "Epoch 190/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.0590\n",
      "\n",
      "Epoch 00190: loss improved from 1.06580 to 1.05902, saving model to weights2-improvement-190-1.0590.hdf5\n",
      "Epoch 191/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.0509\n",
      "\n",
      "Epoch 00191: loss improved from 1.05902 to 1.05094, saving model to weights2-improvement-191-1.0509.hdf5\n",
      "Epoch 192/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.0355\n",
      "\n",
      "Epoch 00192: loss improved from 1.05094 to 1.03553, saving model to weights2-improvement-192-1.0355.hdf5\n",
      "Epoch 193/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.0230\n",
      "\n",
      "Epoch 00193: loss improved from 1.03553 to 1.02298, saving model to weights2-improvement-193-1.0230.hdf5\n",
      "Epoch 194/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.0178\n",
      "\n",
      "Epoch 00194: loss improved from 1.02298 to 1.01783, saving model to weights2-improvement-194-1.0178.hdf5\n",
      "Epoch 195/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.0064\n",
      "\n",
      "Epoch 00195: loss improved from 1.01783 to 1.00639, saving model to weights2-improvement-195-1.0064.hdf5\n",
      "Epoch 196/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 1.0001\n",
      "\n",
      "Epoch 00196: loss improved from 1.00639 to 1.00010, saving model to weights2-improvement-196-1.0001.hdf5\n",
      "Epoch 197/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.9976\n",
      "\n",
      "Epoch 00197: loss improved from 1.00010 to 0.99762, saving model to weights2-improvement-197-0.9976.hdf5\n",
      "Epoch 198/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.9803\n",
      "\n",
      "Epoch 00198: loss improved from 0.99762 to 0.98034, saving model to weights2-improvement-198-0.9803.hdf5\n",
      "Epoch 199/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.9702\n",
      "\n",
      "Epoch 00199: loss improved from 0.98034 to 0.97023, saving model to weights2-improvement-199-0.9702.hdf5\n",
      "Epoch 200/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.9694\n",
      "\n",
      "Epoch 00200: loss improved from 0.97023 to 0.96938, saving model to weights2-improvement-200-0.9694.hdf5\n",
      "Epoch 201/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.9658\n",
      "\n",
      "Epoch 00201: loss improved from 0.96938 to 0.96584, saving model to weights2-improvement-201-0.9658.hdf5\n",
      "Epoch 202/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.9514\n",
      "\n",
      "Epoch 00202: loss improved from 0.96584 to 0.95141, saving model to weights2-improvement-202-0.9514.hdf5\n",
      "Epoch 203/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.9464\n",
      "\n",
      "Epoch 00203: loss improved from 0.95141 to 0.94635, saving model to weights2-improvement-203-0.9464.hdf5\n",
      "Epoch 204/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.9355\n",
      "\n",
      "Epoch 00204: loss improved from 0.94635 to 0.93551, saving model to weights2-improvement-204-0.9355.hdf5\n",
      "Epoch 205/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.9144\n",
      "\n",
      "Epoch 00205: loss improved from 0.93551 to 0.91438, saving model to weights2-improvement-205-0.9144.hdf5\n",
      "Epoch 206/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.9173\n",
      "\n",
      "Epoch 00206: loss did not improve\n",
      "Epoch 207/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.9083\n",
      "\n",
      "Epoch 00207: loss improved from 0.91438 to 0.90834, saving model to weights2-improvement-207-0.9083.hdf5\n",
      "Epoch 208/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.8993\n",
      "\n",
      "Epoch 00208: loss improved from 0.90834 to 0.89933, saving model to weights2-improvement-208-0.8993.hdf5\n",
      "Epoch 209/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.8901\n",
      "\n",
      "Epoch 00209: loss improved from 0.89933 to 0.89009, saving model to weights2-improvement-209-0.8901.hdf5\n",
      "Epoch 210/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.8787\n",
      "\n",
      "Epoch 00210: loss improved from 0.89009 to 0.87872, saving model to weights2-improvement-210-0.8787.hdf5\n",
      "Epoch 211/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.8719\n",
      "\n",
      "Epoch 00211: loss improved from 0.87872 to 0.87187, saving model to weights2-improvement-211-0.8719.hdf5\n",
      "Epoch 212/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.8617\n",
      "\n",
      "Epoch 00212: loss improved from 0.87187 to 0.86168, saving model to weights2-improvement-212-0.8617.hdf5\n",
      "Epoch 213/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.8609\n",
      "\n",
      "Epoch 00213: loss improved from 0.86168 to 0.86087, saving model to weights2-improvement-213-0.8609.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.8491\n",
      "\n",
      "Epoch 00214: loss improved from 0.86087 to 0.84909, saving model to weights2-improvement-214-0.8491.hdf5\n",
      "Epoch 215/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.8398\n",
      "\n",
      "Epoch 00215: loss improved from 0.84909 to 0.83981, saving model to weights2-improvement-215-0.8398.hdf5\n",
      "Epoch 216/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.8339\n",
      "\n",
      "Epoch 00216: loss improved from 0.83981 to 0.83392, saving model to weights2-improvement-216-0.8339.hdf5\n",
      "Epoch 217/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.8244\n",
      "\n",
      "Epoch 00217: loss improved from 0.83392 to 0.82436, saving model to weights2-improvement-217-0.8244.hdf5\n",
      "Epoch 218/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.8164\n",
      "\n",
      "Epoch 00218: loss improved from 0.82436 to 0.81640, saving model to weights2-improvement-218-0.8164.hdf5\n",
      "Epoch 219/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.8121\n",
      "\n",
      "Epoch 00219: loss improved from 0.81640 to 0.81213, saving model to weights2-improvement-219-0.8121.hdf5\n",
      "Epoch 220/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.8022\n",
      "\n",
      "Epoch 00220: loss improved from 0.81213 to 0.80224, saving model to weights2-improvement-220-0.8022.hdf5\n",
      "Epoch 221/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.7852\n",
      "\n",
      "Epoch 00221: loss improved from 0.80224 to 0.78524, saving model to weights2-improvement-221-0.7852.hdf5\n",
      "Epoch 222/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.7800\n",
      "\n",
      "Epoch 00222: loss improved from 0.78524 to 0.77996, saving model to weights2-improvement-222-0.7800.hdf5\n",
      "Epoch 223/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.7743\n",
      "\n",
      "Epoch 00223: loss improved from 0.77996 to 0.77427, saving model to weights2-improvement-223-0.7743.hdf5\n",
      "Epoch 224/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.7722\n",
      "\n",
      "Epoch 00224: loss improved from 0.77427 to 0.77221, saving model to weights2-improvement-224-0.7722.hdf5\n",
      "Epoch 225/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.7646\n",
      "\n",
      "Epoch 00225: loss improved from 0.77221 to 0.76460, saving model to weights2-improvement-225-0.7646.hdf5\n",
      "Epoch 226/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.7569\n",
      "\n",
      "Epoch 00226: loss improved from 0.76460 to 0.75691, saving model to weights2-improvement-226-0.7569.hdf5\n",
      "Epoch 227/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.7528\n",
      "\n",
      "Epoch 00227: loss improved from 0.75691 to 0.75279, saving model to weights2-improvement-227-0.7528.hdf5\n",
      "Epoch 228/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.7420\n",
      "\n",
      "Epoch 00228: loss improved from 0.75279 to 0.74195, saving model to weights2-improvement-228-0.7420.hdf5\n",
      "Epoch 229/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.7257\n",
      "\n",
      "Epoch 00229: loss improved from 0.74195 to 0.72570, saving model to weights2-improvement-229-0.7257.hdf5\n",
      "Epoch 230/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.7298\n",
      "\n",
      "Epoch 00230: loss did not improve\n",
      "Epoch 231/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.7209\n",
      "\n",
      "Epoch 00231: loss improved from 0.72570 to 0.72094, saving model to weights2-improvement-231-0.7209.hdf5\n",
      "Epoch 232/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.7118\n",
      "\n",
      "Epoch 00232: loss improved from 0.72094 to 0.71176, saving model to weights2-improvement-232-0.7118.hdf5\n",
      "Epoch 233/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.6952\n",
      "\n",
      "Epoch 00233: loss improved from 0.71176 to 0.69524, saving model to weights2-improvement-233-0.6952.hdf5\n",
      "Epoch 234/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.7011\n",
      "\n",
      "Epoch 00234: loss did not improve\n",
      "Epoch 235/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.7005\n",
      "\n",
      "Epoch 00235: loss did not improve\n",
      "Epoch 236/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.6804\n",
      "\n",
      "Epoch 00236: loss improved from 0.69524 to 0.68040, saving model to weights2-improvement-236-0.6804.hdf5\n",
      "Epoch 237/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.6847\n",
      "\n",
      "Epoch 00237: loss did not improve\n",
      "Epoch 238/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.6703\n",
      "\n",
      "Epoch 00238: loss improved from 0.68040 to 0.67026, saving model to weights2-improvement-238-0.6703.hdf5\n",
      "Epoch 239/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.6758\n",
      "\n",
      "Epoch 00239: loss did not improve\n",
      "Epoch 240/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.6569\n",
      "\n",
      "Epoch 00240: loss improved from 0.67026 to 0.65688, saving model to weights2-improvement-240-0.6569.hdf5\n",
      "Epoch 241/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.6574\n",
      "\n",
      "Epoch 00241: loss did not improve\n",
      "Epoch 242/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.6400\n",
      "\n",
      "Epoch 00242: loss improved from 0.65688 to 0.64001, saving model to weights2-improvement-242-0.6400.hdf5\n",
      "Epoch 243/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.6362\n",
      "\n",
      "Epoch 00243: loss improved from 0.64001 to 0.63616, saving model to weights2-improvement-243-0.6362.hdf5\n",
      "Epoch 244/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.6312\n",
      "\n",
      "Epoch 00244: loss improved from 0.63616 to 0.63117, saving model to weights2-improvement-244-0.6312.hdf5\n",
      "Epoch 245/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.6286\n",
      "\n",
      "Epoch 00245: loss improved from 0.63117 to 0.62858, saving model to weights2-improvement-245-0.6286.hdf5\n",
      "Epoch 246/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.6168\n",
      "\n",
      "Epoch 00246: loss improved from 0.62858 to 0.61681, saving model to weights2-improvement-246-0.6168.hdf5\n",
      "Epoch 247/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.6152\n",
      "\n",
      "Epoch 00247: loss improved from 0.61681 to 0.61520, saving model to weights2-improvement-247-0.6152.hdf5\n",
      "Epoch 248/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.6072\n",
      "\n",
      "Epoch 00248: loss improved from 0.61520 to 0.60717, saving model to weights2-improvement-248-0.6072.hdf5\n",
      "Epoch 249/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.6055\n",
      "\n",
      "Epoch 00249: loss improved from 0.60717 to 0.60552, saving model to weights2-improvement-249-0.6055.hdf5\n",
      "Epoch 250/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.5881\n",
      "\n",
      "Epoch 00250: loss improved from 0.60552 to 0.58808, saving model to weights2-improvement-250-0.5881.hdf5\n",
      "Epoch 251/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.5878\n",
      "\n",
      "Epoch 00251: loss improved from 0.58808 to 0.58777, saving model to weights2-improvement-251-0.5878.hdf5\n",
      "Epoch 252/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.5902\n",
      "\n",
      "Epoch 00252: loss did not improve\n",
      "Epoch 253/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.5736\n",
      "\n",
      "Epoch 00253: loss improved from 0.58777 to 0.57364, saving model to weights2-improvement-253-0.5736.hdf5\n",
      "Epoch 254/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.5647\n",
      "\n",
      "Epoch 00254: loss improved from 0.57364 to 0.56474, saving model to weights2-improvement-254-0.5647.hdf5\n",
      "Epoch 255/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.5662\n",
      "\n",
      "Epoch 00255: loss did not improve\n",
      "Epoch 256/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.5628\n",
      "\n",
      "Epoch 00256: loss improved from 0.56474 to 0.56284, saving model to weights2-improvement-256-0.5628.hdf5\n",
      "Epoch 257/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.5594\n",
      "\n",
      "Epoch 00257: loss improved from 0.56284 to 0.55938, saving model to weights2-improvement-257-0.5594.hdf5\n",
      "Epoch 258/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.5481\n",
      "\n",
      "Epoch 00258: loss improved from 0.55938 to 0.54812, saving model to weights2-improvement-258-0.5481.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.5425\n",
      "\n",
      "Epoch 00259: loss improved from 0.54812 to 0.54255, saving model to weights2-improvement-259-0.5425.hdf5\n",
      "Epoch 260/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.5376\n",
      "\n",
      "Epoch 00260: loss improved from 0.54255 to 0.53759, saving model to weights2-improvement-260-0.5376.hdf5\n",
      "Epoch 261/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.5345\n",
      "\n",
      "Epoch 00261: loss improved from 0.53759 to 0.53453, saving model to weights2-improvement-261-0.5345.hdf5\n",
      "Epoch 262/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.5278\n",
      "\n",
      "Epoch 00262: loss improved from 0.53453 to 0.52775, saving model to weights2-improvement-262-0.5278.hdf5\n",
      "Epoch 263/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.5212\n",
      "\n",
      "Epoch 00263: loss improved from 0.52775 to 0.52122, saving model to weights2-improvement-263-0.5212.hdf5\n",
      "Epoch 264/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.5171\n",
      "\n",
      "Epoch 00264: loss improved from 0.52122 to 0.51712, saving model to weights2-improvement-264-0.5171.hdf5\n",
      "Epoch 265/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.5169\n",
      "\n",
      "Epoch 00265: loss improved from 0.51712 to 0.51692, saving model to weights2-improvement-265-0.5169.hdf5\n",
      "Epoch 266/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.5038\n",
      "\n",
      "Epoch 00266: loss improved from 0.51692 to 0.50380, saving model to weights2-improvement-266-0.5038.hdf5\n",
      "Epoch 267/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4992\n",
      "\n",
      "Epoch 00267: loss improved from 0.50380 to 0.49925, saving model to weights2-improvement-267-0.4992.hdf5\n",
      "Epoch 268/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4979\n",
      "\n",
      "Epoch 00268: loss improved from 0.49925 to 0.49793, saving model to weights2-improvement-268-0.4979.hdf5\n",
      "Epoch 269/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4957\n",
      "\n",
      "Epoch 00269: loss improved from 0.49793 to 0.49567, saving model to weights2-improvement-269-0.4957.hdf5\n",
      "Epoch 270/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4809\n",
      "\n",
      "Epoch 00270: loss improved from 0.49567 to 0.48088, saving model to weights2-improvement-270-0.4809.hdf5\n",
      "Epoch 271/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4879\n",
      "\n",
      "Epoch 00271: loss did not improve\n",
      "Epoch 272/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4737\n",
      "\n",
      "Epoch 00272: loss improved from 0.48088 to 0.47366, saving model to weights2-improvement-272-0.4737.hdf5\n",
      "Epoch 273/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4657\n",
      "\n",
      "Epoch 00273: loss improved from 0.47366 to 0.46566, saving model to weights2-improvement-273-0.4657.hdf5\n",
      "Epoch 274/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4608\n",
      "\n",
      "Epoch 00274: loss improved from 0.46566 to 0.46075, saving model to weights2-improvement-274-0.4608.hdf5\n",
      "Epoch 275/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4703\n",
      "\n",
      "Epoch 00275: loss did not improve\n",
      "Epoch 276/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4625\n",
      "\n",
      "Epoch 00276: loss did not improve\n",
      "Epoch 277/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4550\n",
      "\n",
      "Epoch 00277: loss improved from 0.46075 to 0.45500, saving model to weights2-improvement-277-0.4550.hdf5\n",
      "Epoch 278/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4543\n",
      "\n",
      "Epoch 00278: loss improved from 0.45500 to 0.45434, saving model to weights2-improvement-278-0.4543.hdf5\n",
      "Epoch 279/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4473\n",
      "\n",
      "Epoch 00279: loss improved from 0.45434 to 0.44731, saving model to weights2-improvement-279-0.4473.hdf5\n",
      "Epoch 280/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4346\n",
      "\n",
      "Epoch 00280: loss improved from 0.44731 to 0.43460, saving model to weights2-improvement-280-0.4346.hdf5\n",
      "Epoch 281/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4426\n",
      "\n",
      "Epoch 00281: loss did not improve\n",
      "Epoch 282/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4341\n",
      "\n",
      "Epoch 00282: loss improved from 0.43460 to 0.43411, saving model to weights2-improvement-282-0.4341.hdf5\n",
      "Epoch 283/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4269\n",
      "\n",
      "Epoch 00283: loss improved from 0.43411 to 0.42694, saving model to weights2-improvement-283-0.4269.hdf5\n",
      "Epoch 284/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4173\n",
      "\n",
      "Epoch 00284: loss improved from 0.42694 to 0.41732, saving model to weights2-improvement-284-0.4173.hdf5\n",
      "Epoch 285/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4289\n",
      "\n",
      "Epoch 00285: loss did not improve\n",
      "Epoch 286/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4175\n",
      "\n",
      "Epoch 00286: loss did not improve\n",
      "Epoch 287/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4068\n",
      "\n",
      "Epoch 00287: loss improved from 0.41732 to 0.40677, saving model to weights2-improvement-287-0.4068.hdf5\n",
      "Epoch 288/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4064\n",
      "\n",
      "Epoch 00288: loss improved from 0.40677 to 0.40645, saving model to weights2-improvement-288-0.4064.hdf5\n",
      "Epoch 289/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4050\n",
      "\n",
      "Epoch 00289: loss improved from 0.40645 to 0.40497, saving model to weights2-improvement-289-0.4050.hdf5\n",
      "Epoch 290/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.4055\n",
      "\n",
      "Epoch 00290: loss did not improve\n",
      "Epoch 291/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3956\n",
      "\n",
      "Epoch 00291: loss improved from 0.40497 to 0.39557, saving model to weights2-improvement-291-0.3956.hdf5\n",
      "Epoch 292/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3858\n",
      "\n",
      "Epoch 00292: loss improved from 0.39557 to 0.38580, saving model to weights2-improvement-292-0.3858.hdf5\n",
      "Epoch 293/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3905\n",
      "\n",
      "Epoch 00293: loss did not improve\n",
      "Epoch 294/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3824\n",
      "\n",
      "Epoch 00294: loss improved from 0.38580 to 0.38239, saving model to weights2-improvement-294-0.3824.hdf5\n",
      "Epoch 295/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3827\n",
      "\n",
      "Epoch 00295: loss did not improve\n",
      "Epoch 296/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3767\n",
      "\n",
      "Epoch 00296: loss improved from 0.38239 to 0.37675, saving model to weights2-improvement-296-0.3767.hdf5\n",
      "Epoch 297/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3745\n",
      "\n",
      "Epoch 00297: loss improved from 0.37675 to 0.37448, saving model to weights2-improvement-297-0.3745.hdf5\n",
      "Epoch 298/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3679\n",
      "\n",
      "Epoch 00298: loss improved from 0.37448 to 0.36792, saving model to weights2-improvement-298-0.3679.hdf5\n",
      "Epoch 299/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3675\n",
      "\n",
      "Epoch 00299: loss improved from 0.36792 to 0.36755, saving model to weights2-improvement-299-0.3675.hdf5\n",
      "Epoch 300/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3632\n",
      "\n",
      "Epoch 00300: loss improved from 0.36755 to 0.36319, saving model to weights2-improvement-300-0.3632.hdf5\n",
      "Epoch 301/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3644\n",
      "\n",
      "Epoch 00301: loss did not improve\n",
      "Epoch 302/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3564\n",
      "\n",
      "Epoch 00302: loss improved from 0.36319 to 0.35641, saving model to weights2-improvement-302-0.3564.hdf5\n",
      "Epoch 303/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3472\n",
      "\n",
      "Epoch 00303: loss improved from 0.35641 to 0.34721, saving model to weights2-improvement-303-0.3472.hdf5\n",
      "Epoch 304/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3503\n",
      "\n",
      "Epoch 00304: loss did not improve\n",
      "Epoch 305/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3519\n",
      "\n",
      "Epoch 00305: loss did not improve\n",
      "Epoch 306/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3407\n",
      "\n",
      "Epoch 00306: loss improved from 0.34721 to 0.34073, saving model to weights2-improvement-306-0.3407.hdf5\n",
      "Epoch 307/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3417\n",
      "\n",
      "Epoch 00307: loss did not improve\n",
      "Epoch 308/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3393\n",
      "\n",
      "Epoch 00308: loss improved from 0.34073 to 0.33934, saving model to weights2-improvement-308-0.3393.hdf5\n",
      "Epoch 309/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3297\n",
      "\n",
      "Epoch 00309: loss improved from 0.33934 to 0.32966, saving model to weights2-improvement-309-0.3297.hdf5\n",
      "Epoch 310/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3350\n",
      "\n",
      "Epoch 00310: loss did not improve\n",
      "Epoch 311/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3253\n",
      "\n",
      "Epoch 00311: loss improved from 0.32966 to 0.32532, saving model to weights2-improvement-311-0.3253.hdf5\n",
      "Epoch 312/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3219\n",
      "\n",
      "Epoch 00312: loss improved from 0.32532 to 0.32191, saving model to weights2-improvement-312-0.3219.hdf5\n",
      "Epoch 313/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3244\n",
      "\n",
      "Epoch 00313: loss did not improve\n",
      "Epoch 314/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3212\n",
      "\n",
      "Epoch 00314: loss improved from 0.32191 to 0.32123, saving model to weights2-improvement-314-0.3212.hdf5\n",
      "Epoch 315/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3203\n",
      "\n",
      "Epoch 00315: loss improved from 0.32123 to 0.32033, saving model to weights2-improvement-315-0.3203.hdf5\n",
      "Epoch 316/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3157\n",
      "\n",
      "Epoch 00316: loss improved from 0.32033 to 0.31572, saving model to weights2-improvement-316-0.3157.hdf5\n",
      "Epoch 317/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3094\n",
      "\n",
      "Epoch 00317: loss improved from 0.31572 to 0.30938, saving model to weights2-improvement-317-0.3094.hdf5\n",
      "Epoch 318/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3112\n",
      "\n",
      "Epoch 00318: loss did not improve\n",
      "Epoch 319/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3038\n",
      "\n",
      "Epoch 00319: loss improved from 0.30938 to 0.30381, saving model to weights2-improvement-319-0.3038.hdf5\n",
      "Epoch 320/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3090\n",
      "\n",
      "Epoch 00320: loss did not improve\n",
      "Epoch 321/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.3077\n",
      "\n",
      "Epoch 00321: loss did not improve\n",
      "Epoch 322/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2960\n",
      "\n",
      "Epoch 00322: loss improved from 0.30381 to 0.29602, saving model to weights2-improvement-322-0.2960.hdf5\n",
      "Epoch 323/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2957\n",
      "\n",
      "Epoch 00323: loss improved from 0.29602 to 0.29570, saving model to weights2-improvement-323-0.2957.hdf5\n",
      "Epoch 324/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2966\n",
      "\n",
      "Epoch 00324: loss did not improve\n",
      "Epoch 325/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2942\n",
      "\n",
      "Epoch 00325: loss improved from 0.29570 to 0.29424, saving model to weights2-improvement-325-0.2942.hdf5\n",
      "Epoch 326/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2898\n",
      "\n",
      "Epoch 00326: loss improved from 0.29424 to 0.28978, saving model to weights2-improvement-326-0.2898.hdf5\n",
      "Epoch 327/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2813\n",
      "\n",
      "Epoch 00327: loss improved from 0.28978 to 0.28135, saving model to weights2-improvement-327-0.2813.hdf5\n",
      "Epoch 328/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2848\n",
      "\n",
      "Epoch 00328: loss did not improve\n",
      "Epoch 329/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2821\n",
      "\n",
      "Epoch 00329: loss did not improve\n",
      "Epoch 330/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2773\n",
      "\n",
      "Epoch 00330: loss improved from 0.28135 to 0.27733, saving model to weights2-improvement-330-0.2773.hdf5\n",
      "Epoch 331/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2782\n",
      "\n",
      "Epoch 00331: loss did not improve\n",
      "Epoch 332/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2780\n",
      "\n",
      "Epoch 00332: loss did not improve\n",
      "Epoch 333/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2712\n",
      "\n",
      "Epoch 00333: loss improved from 0.27733 to 0.27117, saving model to weights2-improvement-333-0.2712.hdf5\n",
      "Epoch 334/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2693\n",
      "\n",
      "Epoch 00334: loss improved from 0.27117 to 0.26932, saving model to weights2-improvement-334-0.2693.hdf5\n",
      "Epoch 335/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2649\n",
      "\n",
      "Epoch 00335: loss improved from 0.26932 to 0.26490, saving model to weights2-improvement-335-0.2649.hdf5\n",
      "Epoch 336/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2645\n",
      "\n",
      "Epoch 00336: loss improved from 0.26490 to 0.26448, saving model to weights2-improvement-336-0.2645.hdf5\n",
      "Epoch 337/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2664\n",
      "\n",
      "Epoch 00337: loss did not improve\n",
      "Epoch 338/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2580\n",
      "\n",
      "Epoch 00338: loss improved from 0.26448 to 0.25801, saving model to weights2-improvement-338-0.2580.hdf5\n",
      "Epoch 339/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2635\n",
      "\n",
      "Epoch 00339: loss did not improve\n",
      "Epoch 340/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2590\n",
      "\n",
      "Epoch 00340: loss did not improve\n",
      "Epoch 341/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2486\n",
      "\n",
      "Epoch 00341: loss improved from 0.25801 to 0.24858, saving model to weights2-improvement-341-0.2486.hdf5\n",
      "Epoch 342/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2544\n",
      "\n",
      "Epoch 00342: loss did not improve\n",
      "Epoch 343/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2468\n",
      "\n",
      "Epoch 00343: loss improved from 0.24858 to 0.24681, saving model to weights2-improvement-343-0.2468.hdf5\n",
      "Epoch 344/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2556\n",
      "\n",
      "Epoch 00344: loss did not improve\n",
      "Epoch 345/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2478\n",
      "\n",
      "Epoch 00345: loss did not improve\n",
      "Epoch 346/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2430\n",
      "\n",
      "Epoch 00346: loss improved from 0.24681 to 0.24298, saving model to weights2-improvement-346-0.2430.hdf5\n",
      "Epoch 347/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2406\n",
      "\n",
      "Epoch 00347: loss improved from 0.24298 to 0.24062, saving model to weights2-improvement-347-0.2406.hdf5\n",
      "Epoch 348/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2417\n",
      "\n",
      "Epoch 00348: loss did not improve\n",
      "Epoch 349/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2323\n",
      "\n",
      "Epoch 00349: loss improved from 0.24062 to 0.23228, saving model to weights2-improvement-349-0.2323.hdf5\n",
      "Epoch 350/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2379\n",
      "\n",
      "Epoch 00350: loss did not improve\n",
      "Epoch 351/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2364\n",
      "\n",
      "Epoch 00351: loss did not improve\n",
      "Epoch 352/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2367\n",
      "\n",
      "Epoch 00352: loss did not improve\n",
      "Epoch 353/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2307\n",
      "\n",
      "Epoch 00353: loss improved from 0.23228 to 0.23073, saving model to weights2-improvement-353-0.2307.hdf5\n",
      "Epoch 354/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2343\n",
      "\n",
      "Epoch 00354: loss did not improve\n",
      "Epoch 355/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2304\n",
      "\n",
      "Epoch 00355: loss improved from 0.23073 to 0.23041, saving model to weights2-improvement-355-0.2304.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2345\n",
      "\n",
      "Epoch 00356: loss did not improve\n",
      "Epoch 357/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2154\n",
      "\n",
      "Epoch 00357: loss improved from 0.23041 to 0.21543, saving model to weights2-improvement-357-0.2154.hdf5\n",
      "Epoch 358/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2249\n",
      "\n",
      "Epoch 00358: loss did not improve\n",
      "Epoch 359/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2290\n",
      "\n",
      "Epoch 00359: loss did not improve\n",
      "Epoch 360/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2177\n",
      "\n",
      "Epoch 00360: loss did not improve\n",
      "Epoch 361/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2129\n",
      "\n",
      "Epoch 00361: loss improved from 0.21543 to 0.21294, saving model to weights2-improvement-361-0.2129.hdf5\n",
      "Epoch 362/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2164\n",
      "\n",
      "Epoch 00362: loss did not improve\n",
      "Epoch 363/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2148\n",
      "\n",
      "Epoch 00363: loss did not improve\n",
      "Epoch 364/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2182\n",
      "\n",
      "Epoch 00364: loss did not improve\n",
      "Epoch 365/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2189\n",
      "\n",
      "Epoch 00365: loss did not improve\n",
      "Epoch 366/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2095\n",
      "\n",
      "Epoch 00366: loss improved from 0.21294 to 0.20953, saving model to weights2-improvement-366-0.2095.hdf5\n",
      "Epoch 367/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2066\n",
      "\n",
      "Epoch 00367: loss improved from 0.20953 to 0.20657, saving model to weights2-improvement-367-0.2066.hdf5\n",
      "Epoch 368/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2052\n",
      "\n",
      "Epoch 00368: loss improved from 0.20657 to 0.20518, saving model to weights2-improvement-368-0.2052.hdf5\n",
      "Epoch 369/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2069\n",
      "\n",
      "Epoch 00369: loss did not improve\n",
      "Epoch 370/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2020\n",
      "\n",
      "Epoch 00370: loss improved from 0.20518 to 0.20202, saving model to weights2-improvement-370-0.2020.hdf5\n",
      "Epoch 371/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2015\n",
      "\n",
      "Epoch 00371: loss improved from 0.20202 to 0.20153, saving model to weights2-improvement-371-0.2015.hdf5\n",
      "Epoch 372/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2000\n",
      "\n",
      "Epoch 00372: loss improved from 0.20153 to 0.20002, saving model to weights2-improvement-372-0.2000.hdf5\n",
      "Epoch 373/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1981\n",
      "\n",
      "Epoch 00373: loss improved from 0.20002 to 0.19811, saving model to weights2-improvement-373-0.1981.hdf5\n",
      "Epoch 374/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2034\n",
      "\n",
      "Epoch 00374: loss did not improve\n",
      "Epoch 375/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.2000\n",
      "\n",
      "Epoch 00375: loss did not improve\n",
      "Epoch 376/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1985\n",
      "\n",
      "Epoch 00376: loss did not improve\n",
      "Epoch 377/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1872\n",
      "\n",
      "Epoch 00377: loss improved from 0.19811 to 0.18720, saving model to weights2-improvement-377-0.1872.hdf5\n",
      "Epoch 378/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1939\n",
      "\n",
      "Epoch 00378: loss did not improve\n",
      "Epoch 379/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1974\n",
      "\n",
      "Epoch 00379: loss did not improve\n",
      "Epoch 380/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1940\n",
      "\n",
      "Epoch 00380: loss did not improve\n",
      "Epoch 381/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1962\n",
      "\n",
      "Epoch 00381: loss did not improve\n",
      "Epoch 382/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1947\n",
      "\n",
      "Epoch 00382: loss did not improve\n",
      "Epoch 383/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1847\n",
      "\n",
      "Epoch 00383: loss improved from 0.18720 to 0.18466, saving model to weights2-improvement-383-0.1847.hdf5\n",
      "Epoch 384/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1770\n",
      "\n",
      "Epoch 00384: loss improved from 0.18466 to 0.17701, saving model to weights2-improvement-384-0.1770.hdf5\n",
      "Epoch 385/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1885\n",
      "\n",
      "Epoch 00385: loss did not improve\n",
      "Epoch 386/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1800\n",
      "\n",
      "Epoch 00386: loss did not improve\n",
      "Epoch 387/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1894\n",
      "\n",
      "Epoch 00387: loss did not improve\n",
      "Epoch 388/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1849\n",
      "\n",
      "Epoch 00388: loss did not improve\n",
      "Epoch 389/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1816\n",
      "\n",
      "Epoch 00389: loss did not improve\n",
      "Epoch 390/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1863\n",
      "\n",
      "Epoch 00390: loss did not improve\n",
      "Epoch 391/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1704\n",
      "\n",
      "Epoch 00391: loss improved from 0.17701 to 0.17045, saving model to weights2-improvement-391-0.1704.hdf5\n",
      "Epoch 392/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1788\n",
      "\n",
      "Epoch 00392: loss did not improve\n",
      "Epoch 393/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1717\n",
      "\n",
      "Epoch 00393: loss did not improve\n",
      "Epoch 394/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1691\n",
      "\n",
      "Epoch 00394: loss improved from 0.17045 to 0.16910, saving model to weights2-improvement-394-0.1691.hdf5\n",
      "Epoch 395/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1798\n",
      "\n",
      "Epoch 00395: loss did not improve\n",
      "Epoch 396/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1758\n",
      "\n",
      "Epoch 00396: loss did not improve\n",
      "Epoch 397/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1668\n",
      "\n",
      "Epoch 00397: loss improved from 0.16910 to 0.16680, saving model to weights2-improvement-397-0.1668.hdf5\n",
      "Epoch 398/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1616\n",
      "\n",
      "Epoch 00398: loss improved from 0.16680 to 0.16164, saving model to weights2-improvement-398-0.1616.hdf5\n",
      "Epoch 399/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1679\n",
      "\n",
      "Epoch 00399: loss did not improve\n",
      "Epoch 400/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1682\n",
      "\n",
      "Epoch 00400: loss did not improve\n",
      "Epoch 401/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1753\n",
      "\n",
      "Epoch 00401: loss did not improve\n",
      "Epoch 402/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1732\n",
      "\n",
      "Epoch 00402: loss did not improve\n",
      "Epoch 403/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1620\n",
      "\n",
      "Epoch 00403: loss did not improve\n",
      "Epoch 404/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1654\n",
      "\n",
      "Epoch 00404: loss did not improve\n",
      "Epoch 405/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1594\n",
      "\n",
      "Epoch 00405: loss improved from 0.16164 to 0.15938, saving model to weights2-improvement-405-0.1594.hdf5\n",
      "Epoch 406/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1566\n",
      "\n",
      "Epoch 00406: loss improved from 0.15938 to 0.15661, saving model to weights2-improvement-406-0.1566.hdf5\n",
      "Epoch 407/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1645\n",
      "\n",
      "Epoch 00407: loss did not improve\n",
      "Epoch 408/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1610\n",
      "\n",
      "Epoch 00408: loss did not improve\n",
      "Epoch 409/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1633\n",
      "\n",
      "Epoch 00409: loss did not improve\n",
      "Epoch 410/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1552\n",
      "\n",
      "Epoch 00410: loss improved from 0.15661 to 0.15523, saving model to weights2-improvement-410-0.1552.hdf5\n",
      "Epoch 411/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1550\n",
      "\n",
      "Epoch 00411: loss improved from 0.15523 to 0.15504, saving model to weights2-improvement-411-0.1550.hdf5\n",
      "Epoch 412/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1526\n",
      "\n",
      "Epoch 00412: loss improved from 0.15504 to 0.15262, saving model to weights2-improvement-412-0.1526.hdf5\n",
      "Epoch 413/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1614\n",
      "\n",
      "Epoch 00413: loss did not improve\n",
      "Epoch 414/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1608\n",
      "\n",
      "Epoch 00414: loss did not improve\n",
      "Epoch 415/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1583\n",
      "\n",
      "Epoch 00415: loss did not improve\n",
      "Epoch 416/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1550\n",
      "\n",
      "Epoch 00416: loss did not improve\n",
      "Epoch 417/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1479\n",
      "\n",
      "Epoch 00417: loss improved from 0.15262 to 0.14795, saving model to weights2-improvement-417-0.1479.hdf5\n",
      "Epoch 418/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1501\n",
      "\n",
      "Epoch 00418: loss did not improve\n",
      "Epoch 419/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1514\n",
      "\n",
      "Epoch 00419: loss did not improve\n",
      "Epoch 420/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1543\n",
      "\n",
      "Epoch 00420: loss did not improve\n",
      "Epoch 421/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1527\n",
      "\n",
      "Epoch 00421: loss did not improve\n",
      "Epoch 422/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1480\n",
      "\n",
      "Epoch 00422: loss did not improve\n",
      "Epoch 423/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1453\n",
      "\n",
      "Epoch 00423: loss improved from 0.14795 to 0.14530, saving model to weights2-improvement-423-0.1453.hdf5\n",
      "Epoch 424/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1458\n",
      "\n",
      "Epoch 00424: loss did not improve\n",
      "Epoch 425/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1449\n",
      "\n",
      "Epoch 00425: loss improved from 0.14530 to 0.14489, saving model to weights2-improvement-425-0.1449.hdf5\n",
      "Epoch 426/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1438\n",
      "\n",
      "Epoch 00426: loss improved from 0.14489 to 0.14380, saving model to weights2-improvement-426-0.1438.hdf5\n",
      "Epoch 427/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1483\n",
      "\n",
      "Epoch 00427: loss did not improve\n",
      "Epoch 428/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1402\n",
      "\n",
      "Epoch 00428: loss improved from 0.14380 to 0.14024, saving model to weights2-improvement-428-0.1402.hdf5\n",
      "Epoch 429/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1420\n",
      "\n",
      "Epoch 00429: loss did not improve\n",
      "Epoch 430/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1455\n",
      "\n",
      "Epoch 00430: loss did not improve\n",
      "Epoch 431/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1398\n",
      "\n",
      "Epoch 00431: loss improved from 0.14024 to 0.13976, saving model to weights2-improvement-431-0.1398.hdf5\n",
      "Epoch 432/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1404\n",
      "\n",
      "Epoch 00432: loss did not improve\n",
      "Epoch 433/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1438\n",
      "\n",
      "Epoch 00433: loss did not improve\n",
      "Epoch 434/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1430\n",
      "\n",
      "Epoch 00434: loss did not improve\n",
      "Epoch 435/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1396\n",
      "\n",
      "Epoch 00435: loss improved from 0.13976 to 0.13960, saving model to weights2-improvement-435-0.1396.hdf5\n",
      "Epoch 436/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1346\n",
      "\n",
      "Epoch 00436: loss improved from 0.13960 to 0.13459, saving model to weights2-improvement-436-0.1346.hdf5\n",
      "Epoch 437/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1383\n",
      "\n",
      "Epoch 00437: loss did not improve\n",
      "Epoch 438/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1432\n",
      "\n",
      "Epoch 00438: loss did not improve\n",
      "Epoch 439/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1334\n",
      "\n",
      "Epoch 00439: loss improved from 0.13459 to 0.13341, saving model to weights2-improvement-439-0.1334.hdf5\n",
      "Epoch 440/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1374\n",
      "\n",
      "Epoch 00440: loss did not improve\n",
      "Epoch 441/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1304\n",
      "\n",
      "Epoch 00441: loss improved from 0.13341 to 0.13041, saving model to weights2-improvement-441-0.1304.hdf5\n",
      "Epoch 442/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1296\n",
      "\n",
      "Epoch 00442: loss improved from 0.13041 to 0.12964, saving model to weights2-improvement-442-0.1296.hdf5\n",
      "Epoch 443/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1344\n",
      "\n",
      "Epoch 00443: loss did not improve\n",
      "Epoch 444/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1341\n",
      "\n",
      "Epoch 00444: loss did not improve\n",
      "Epoch 445/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1269\n",
      "\n",
      "Epoch 00445: loss improved from 0.12964 to 0.12692, saving model to weights2-improvement-445-0.1269.hdf5\n",
      "Epoch 446/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1334\n",
      "\n",
      "Epoch 00446: loss did not improve\n",
      "Epoch 447/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1301\n",
      "\n",
      "Epoch 00447: loss did not improve\n",
      "Epoch 448/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1258\n",
      "\n",
      "Epoch 00448: loss improved from 0.12692 to 0.12584, saving model to weights2-improvement-448-0.1258.hdf5\n",
      "Epoch 449/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1209\n",
      "\n",
      "Epoch 00449: loss improved from 0.12584 to 0.12086, saving model to weights2-improvement-449-0.1209.hdf5\n",
      "Epoch 450/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1291\n",
      "\n",
      "Epoch 00450: loss did not improve\n",
      "Epoch 451/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1303\n",
      "\n",
      "Epoch 00451: loss did not improve\n",
      "Epoch 452/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1248\n",
      "\n",
      "Epoch 00452: loss did not improve\n",
      "Epoch 453/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1263\n",
      "\n",
      "Epoch 00453: loss did not improve\n",
      "Epoch 454/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1213\n",
      "\n",
      "Epoch 00454: loss did not improve\n",
      "Epoch 455/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1247\n",
      "\n",
      "Epoch 00455: loss did not improve\n",
      "Epoch 456/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1223\n",
      "\n",
      "Epoch 00456: loss did not improve\n",
      "Epoch 457/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1194\n",
      "\n",
      "Epoch 00457: loss improved from 0.12086 to 0.11939, saving model to weights2-improvement-457-0.1194.hdf5\n",
      "Epoch 458/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1261\n",
      "\n",
      "Epoch 00458: loss did not improve\n",
      "Epoch 459/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1278\n",
      "\n",
      "Epoch 00459: loss did not improve\n",
      "Epoch 460/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1165\n",
      "\n",
      "Epoch 00460: loss improved from 0.11939 to 0.11647, saving model to weights2-improvement-460-0.1165.hdf5\n",
      "Epoch 461/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1216\n",
      "\n",
      "Epoch 00461: loss did not improve\n",
      "Epoch 462/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1191\n",
      "\n",
      "Epoch 00462: loss did not improve\n",
      "Epoch 463/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1200\n",
      "\n",
      "Epoch 00463: loss did not improve\n",
      "Epoch 464/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1196\n",
      "\n",
      "Epoch 00464: loss did not improve\n",
      "Epoch 465/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1174\n",
      "\n",
      "Epoch 00465: loss did not improve\n",
      "Epoch 466/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1169\n",
      "\n",
      "Epoch 00466: loss did not improve\n",
      "Epoch 467/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1222\n",
      "\n",
      "Epoch 00467: loss did not improve\n",
      "Epoch 468/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1143\n",
      "\n",
      "Epoch 00468: loss improved from 0.11647 to 0.11435, saving model to weights2-improvement-468-0.1143.hdf5\n",
      "Epoch 469/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1217\n",
      "\n",
      "Epoch 00469: loss did not improve\n",
      "Epoch 470/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1167\n",
      "\n",
      "Epoch 00470: loss did not improve\n",
      "Epoch 471/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1159\n",
      "\n",
      "Epoch 00471: loss did not improve\n",
      "Epoch 472/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1234\n",
      "\n",
      "Epoch 00472: loss did not improve\n",
      "Epoch 473/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1140\n",
      "\n",
      "Epoch 00473: loss improved from 0.11435 to 0.11402, saving model to weights2-improvement-473-0.1140.hdf5\n",
      "Epoch 474/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1143\n",
      "\n",
      "Epoch 00474: loss did not improve\n",
      "Epoch 475/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1130\n",
      "\n",
      "Epoch 00475: loss improved from 0.11402 to 0.11302, saving model to weights2-improvement-475-0.1130.hdf5\n",
      "Epoch 476/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1104\n",
      "\n",
      "Epoch 00476: loss improved from 0.11302 to 0.11043, saving model to weights2-improvement-476-0.1104.hdf5\n",
      "Epoch 477/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1160\n",
      "\n",
      "Epoch 00477: loss did not improve\n",
      "Epoch 478/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1135\n",
      "\n",
      "Epoch 00478: loss did not improve\n",
      "Epoch 479/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1173\n",
      "\n",
      "Epoch 00479: loss did not improve\n",
      "Epoch 480/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1143\n",
      "\n",
      "Epoch 00480: loss did not improve\n",
      "Epoch 481/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1133\n",
      "\n",
      "Epoch 00481: loss did not improve\n",
      "Epoch 482/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1131\n",
      "\n",
      "Epoch 00482: loss did not improve\n",
      "Epoch 483/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1027\n",
      "\n",
      "Epoch 00483: loss improved from 0.11043 to 0.10269, saving model to weights2-improvement-483-0.1027.hdf5\n",
      "Epoch 484/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1054\n",
      "\n",
      "Epoch 00484: loss did not improve\n",
      "Epoch 485/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1145\n",
      "\n",
      "Epoch 00485: loss did not improve\n",
      "Epoch 486/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1034\n",
      "\n",
      "Epoch 00486: loss did not improve\n",
      "Epoch 487/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1119\n",
      "\n",
      "Epoch 00487: loss did not improve\n",
      "Epoch 488/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1064\n",
      "\n",
      "Epoch 00488: loss did not improve\n",
      "Epoch 489/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1057\n",
      "\n",
      "Epoch 00489: loss did not improve\n",
      "Epoch 490/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1079\n",
      "\n",
      "Epoch 00490: loss did not improve\n",
      "Epoch 491/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1106\n",
      "\n",
      "Epoch 00491: loss did not improve\n",
      "Epoch 492/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1093\n",
      "\n",
      "Epoch 00492: loss did not improve\n",
      "Epoch 493/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1035\n",
      "\n",
      "Epoch 00493: loss did not improve\n",
      "Epoch 494/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1028\n",
      "\n",
      "Epoch 00494: loss did not improve\n",
      "Epoch 495/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.0998\n",
      "\n",
      "Epoch 00495: loss improved from 0.10269 to 0.09983, saving model to weights2-improvement-495-0.0998.hdf5\n",
      "Epoch 496/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1038\n",
      "\n",
      "Epoch 00496: loss did not improve\n",
      "Epoch 497/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1012\n",
      "\n",
      "Epoch 00497: loss did not improve\n",
      "Epoch 498/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1071\n",
      "\n",
      "Epoch 00498: loss did not improve\n",
      "Epoch 499/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.0996\n",
      "\n",
      "Epoch 00499: loss improved from 0.09983 to 0.09963, saving model to weights2-improvement-499-0.0996.hdf5\n",
      "Epoch 500/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1023\n",
      "\n",
      "Epoch 00500: loss did not improve\n",
      "Epoch 501/700\n",
      "17409/17409 [==============================] - 63s 4ms/step - loss: 0.1022\n",
      "\n",
      "Epoch 00501: loss did not improve\n",
      "Epoch 502/700\n",
      " 7050/17409 [===========>..................] - ETA: 38s - loss: 0.1117"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-834e732759d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m700\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filepath=\"weights2-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(X, y, epochs=700, batch_size=50, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ' ', 1: \"'\", 2: ',', 3: '-', 4: 'a', 5: 'b', 6: 'c', 7: 'd', 8: 'e', 9: 'f', 10: 'g', 11: 'h', 12: 'i', 13: 'k', 14: 'l', 15: 'm', 16: 'n', 17: 'o', 18: 'p', 19: 'q', 20: 'r', 21: 's', 22: 't', 23: 'u', 24: 'v', 25: 'w', 26: 'y', 27: 'j', 28: 'x', 29: 'z'}\n",
      "{' ': 0, \"'\": 1, ',': 2, '-': 3, 'a': 4, 'b': 5, 'c': 6, 'd': 7, 'e': 8, 'f': 9, 'g': 10, 'h': 11, 'i': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'y': 26, 'j': 27, 'x': 28, 'z': 29}\n"
     ]
    }
   ],
   "source": [
    "print(int_to_char)\n",
    "print(char_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sonnetString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "[12, 21, 0, 12, 22, 0, 22, 11, 26, 0, 25, 12, 14, 14, 2, 0, 22, 11, 26, 0, 12, 15, 4, 10, 8, 0, 21, 11, 17, 23, 14, 7, 0, 13, 8, 8, 18, 0, 17, 18]\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = np.random.randint(0, len(dataX_seq)-1)\n",
    "pattern = dataX_seq[start]\n",
    "print(start)\n",
    "print(pattern)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eeertlng this brt mnt me, nor you ano iooe soans thou ganssy"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(60):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
