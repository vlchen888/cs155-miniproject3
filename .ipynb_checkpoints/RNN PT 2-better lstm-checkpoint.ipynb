{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "import numpy as np\n",
    "from Utility import Utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 layer LST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "util = Utility()\n",
    "sonnets = util.get_shakespeare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnetString = []\n",
    "for i in range(len(sonnets)):\n",
    "    sA = sonnets[i+1]\n",
    "    sonnetString.append(\"\")\n",
    "    for k in sA:\n",
    "        for j in k:\n",
    "            sonnetString[-1] += j + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating entire sonnets\n",
    "int_to_char = {0: ' ', 1: \"'\", 2: ',', 3: '-', 4: 'a', 5: 'b', 6: 'c', 7: 'd', 8: 'e', 9: 'f', 10: 'g', 11: 'h', 12: 'i', 13: 'k', 14: 'l', 15: 'm', 16: 'n', 17: 'o', 18: 'p', 19: 'q', 20: 'r', 21: 's', 22: 't', 23: 'u', 24: 'v', 25: 'w', 26: 'y', 27: 'j', 28: 'x', 29: 'z'}\n",
    "char_to_int = {' ': 0, \"'\": 1, ',': 2, '-': 3, 'a': 4, 'b': 5, 'c': 6, 'd': 7, 'e': 8, 'f': 9, 'g': 10, 'h': 11, 'i': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'y': 26, 'j':27, 'x':28, 'z':29}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "dataX = []\n",
    "dataY = []\n",
    "dataX_seq = []\n",
    "for iter in range(len(sonnetString)):\n",
    "    raw_text = sonnetString[iter]\n",
    "    n_chars = len(raw_text)\n",
    "    seq_in = raw_text[0:seq_length]\n",
    "    dataX_seq.append([char_to_int[char] for char in seq_in])\n",
    "    for i in range(0, n_chars - seq_length, 5):\n",
    "        seq_in = raw_text[i:i + seq_length]\n",
    "        seq_out = raw_text[i + seq_length]\n",
    "        dataX.append([char_to_int[char] for char in seq_in])\n",
    "        dataY.append(char_to_int[seq_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(dataX, (len(dataX), seq_length, 1))\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "adam = keras.optimizers.Adam(lr = 1e-4)\n",
    "model.load_weights('weights-improvement-33-0.0104.hdf5')\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam)\n",
    "#filename = \"weights-improvement-61-1.4022.hdf5\"\n",
    "#model.load_weights(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "17409/17409 [==============================] - 31s 2ms/step - loss: 0.0307\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.03068, saving model to weights-improvement-01-0.0307.hdf5\n",
      "Epoch 2/60\n",
      "17409/17409 [==============================] - 29s 2ms/step - loss: 0.0291\n",
      "\n",
      "Epoch 00002: loss improved from 0.03068 to 0.02908, saving model to weights-improvement-02-0.0291.hdf5\n",
      "Epoch 3/60\n",
      "17409/17409 [==============================] - 30s 2ms/step - loss: 0.0278\n",
      "\n",
      "Epoch 00003: loss improved from 0.02908 to 0.02784, saving model to weights-improvement-03-0.0278.hdf5\n",
      "Epoch 4/60\n",
      "17409/17409 [==============================] - 29s 2ms/step - loss: 0.0268\n",
      "\n",
      "Epoch 00004: loss improved from 0.02784 to 0.02679, saving model to weights-improvement-04-0.0268.hdf5\n",
      "Epoch 5/60\n",
      "17409/17409 [==============================] - 29s 2ms/step - loss: 0.0262\n",
      "\n",
      "Epoch 00005: loss improved from 0.02679 to 0.02625, saving model to weights-improvement-05-0.0262.hdf5\n",
      "Epoch 6/60\n",
      "17409/17409 [==============================] - 33s 2ms/step - loss: 0.0249\n",
      "\n",
      "Epoch 00006: loss improved from 0.02625 to 0.02487, saving model to weights-improvement-06-0.0249.hdf5\n",
      "Epoch 7/60\n",
      "17409/17409 [==============================] - 29s 2ms/step - loss: 0.0237\n",
      "\n",
      "Epoch 00007: loss improved from 0.02487 to 0.02372, saving model to weights-improvement-07-0.0237.hdf5\n",
      "Epoch 8/60\n",
      "17409/17409 [==============================] - 28s 2ms/step - loss: 0.0233\n",
      "\n",
      "Epoch 00008: loss improved from 0.02372 to 0.02329, saving model to weights-improvement-08-0.0233.hdf5\n",
      "Epoch 9/60\n",
      "17409/17409 [==============================] - 29s 2ms/step - loss: 0.0220\n",
      "\n",
      "Epoch 00009: loss improved from 0.02329 to 0.02197, saving model to weights-improvement-09-0.0220.hdf5\n",
      "Epoch 10/60\n",
      "17409/17409 [==============================] - 33s 2ms/step - loss: 0.0210\n",
      "\n",
      "Epoch 00010: loss improved from 0.02197 to 0.02104, saving model to weights-improvement-10-0.0210.hdf5\n",
      "Epoch 11/60\n",
      "17409/17409 [==============================] - 31s 2ms/step - loss: 0.0212\n",
      "\n",
      "Epoch 00011: loss did not improve\n",
      "Epoch 12/60\n",
      "17409/17409 [==============================] - 29s 2ms/step - loss: 0.0201\n",
      "\n",
      "Epoch 00012: loss improved from 0.02104 to 0.02012, saving model to weights-improvement-12-0.0201.hdf5\n",
      "Epoch 13/60\n",
      "17409/17409 [==============================] - 29s 2ms/step - loss: 0.0195\n",
      "\n",
      "Epoch 00013: loss improved from 0.02012 to 0.01948, saving model to weights-improvement-13-0.0195.hdf5\n",
      "Epoch 14/60\n",
      "17409/17409 [==============================] - 29s 2ms/step - loss: 0.0182\n",
      "\n",
      "Epoch 00014: loss improved from 0.01948 to 0.01820, saving model to weights-improvement-14-0.0182.hdf5\n",
      "Epoch 15/60\n",
      "17409/17409 [==============================] - 36s 2ms/step - loss: 0.0175\n",
      "\n",
      "Epoch 00015: loss improved from 0.01820 to 0.01747, saving model to weights-improvement-15-0.0175.hdf5\n",
      "Epoch 16/60\n",
      "17409/17409 [==============================] - 33s 2ms/step - loss: 0.0168\n",
      "\n",
      "Epoch 00016: loss improved from 0.01747 to 0.01684, saving model to weights-improvement-16-0.0168.hdf5\n",
      "Epoch 17/60\n",
      "17409/17409 [==============================] - 29s 2ms/step - loss: 0.0164\n",
      "\n",
      "Epoch 00017: loss improved from 0.01684 to 0.01637, saving model to weights-improvement-17-0.0164.hdf5\n",
      "Epoch 18/60\n",
      "17409/17409 [==============================] - 29s 2ms/step - loss: 0.0159\n",
      "\n",
      "Epoch 00018: loss improved from 0.01637 to 0.01590, saving model to weights-improvement-18-0.0159.hdf5\n",
      "Epoch 19/60\n",
      "17409/17409 [==============================] - 29s 2ms/step - loss: 0.0156\n",
      "\n",
      "Epoch 00019: loss improved from 0.01590 to 0.01556, saving model to weights-improvement-19-0.0156.hdf5\n",
      "Epoch 20/60\n",
      "17409/17409 [==============================] - 29s 2ms/step - loss: 0.0237\n",
      "\n",
      "Epoch 00020: loss did not improve\n",
      "Epoch 21/60\n",
      "17409/17409 [==============================] - 29s 2ms/step - loss: 0.0233\n",
      "\n",
      "Epoch 00021: loss did not improve\n",
      "Epoch 22/60\n",
      "17409/17409 [==============================] - 29s 2ms/step - loss: 0.0158\n",
      "\n",
      "Epoch 00022: loss did not improve\n",
      "Epoch 23/60\n",
      "17409/17409 [==============================] - 29s 2ms/step - loss: 0.0142\n",
      "\n",
      "Epoch 00023: loss improved from 0.01556 to 0.01416, saving model to weights-improvement-23-0.0142.hdf5\n",
      "Epoch 24/60\n",
      "17409/17409 [==============================] - 29s 2ms/step - loss: 0.0134\n",
      "\n",
      "Epoch 00024: loss improved from 0.01416 to 0.01341, saving model to weights-improvement-24-0.0134.hdf5\n",
      "Epoch 25/60\n",
      "17409/17409 [==============================] - 29s 2ms/step - loss: 0.0129\n",
      "\n",
      "Epoch 00025: loss improved from 0.01341 to 0.01292, saving model to weights-improvement-25-0.0129.hdf5\n",
      "Epoch 26/60\n",
      "17409/17409 [==============================] - 32s 2ms/step - loss: 0.0125\n",
      "\n",
      "Epoch 00026: loss improved from 0.01292 to 0.01251, saving model to weights-improvement-26-0.0125.hdf5\n",
      "Epoch 27/60\n",
      "17409/17409 [==============================] - 40s 2ms/step - loss: 0.0122\n",
      "\n",
      "Epoch 00027: loss improved from 0.01251 to 0.01217, saving model to weights-improvement-27-0.0122.hdf5\n",
      "Epoch 28/60\n",
      "17409/17409 [==============================] - 38s 2ms/step - loss: 0.0118\n",
      "\n",
      "Epoch 00028: loss improved from 0.01217 to 0.01184, saving model to weights-improvement-28-0.0118.hdf5\n",
      "Epoch 29/60\n",
      "17409/17409 [==============================] - 35s 2ms/step - loss: 0.0115\n",
      "\n",
      "Epoch 00029: loss improved from 0.01184 to 0.01152, saving model to weights-improvement-29-0.0115.hdf5\n",
      "Epoch 30/60\n",
      "17409/17409 [==============================] - 35s 2ms/step - loss: 0.0119\n",
      "\n",
      "Epoch 00030: loss did not improve\n",
      "Epoch 31/60\n",
      "17409/17409 [==============================] - 35s 2ms/step - loss: 0.0112\n",
      "\n",
      "Epoch 00031: loss improved from 0.01152 to 0.01123, saving model to weights-improvement-31-0.0112.hdf5\n",
      "Epoch 32/60\n",
      "17409/17409 [==============================] - 35s 2ms/step - loss: 0.0108\n",
      "\n",
      "Epoch 00032: loss improved from 0.01123 to 0.01079, saving model to weights-improvement-32-0.0108.hdf5\n",
      "Epoch 33/60\n",
      "17409/17409 [==============================] - 35s 2ms/step - loss: 0.0104\n",
      "\n",
      "Epoch 00033: loss improved from 0.01079 to 0.01039, saving model to weights-improvement-33-0.0104.hdf5\n",
      "Epoch 34/60\n",
      "17409/17409 [==============================] - 35s 2ms/step - loss: 0.0123\n",
      "\n",
      "Epoch 00034: loss did not improve\n",
      "Epoch 35/60\n",
      " 4700/17409 [=======>......................] - ETA: 27s - loss: 0.0196"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-07221ff70ac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(X, y, epochs=60, batch_size=50, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ' ', 1: \"'\", 2: ',', 3: '-', 4: 'a', 5: 'b', 6: 'c', 7: 'd', 8: 'e', 9: 'f', 10: 'g', 11: 'h', 12: 'i', 13: 'k', 14: 'l', 15: 'm', 16: 'n', 17: 'o', 18: 'p', 19: 'q', 20: 'r', 21: 's', 22: 't', 23: 'u', 24: 'v', 25: 'w', 26: 'y', 27: 'j', 28: 'x', 29: 'z'}\n",
      "{' ': 0, \"'\": 1, ',': 2, '-': 3, 'a': 4, 'b': 5, 'c': 6, 'd': 7, 'e': 8, 'f': 9, 'g': 10, 'h': 11, 'i': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'y': 26, 'j': 27, 'x': 28, 'z': 29}\n"
     ]
    }
   ],
   "source": [
    "print(int_to_char)\n",
    "print(char_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sonnetString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "[14, 12, 13, 8, 0, 4, 21, 0, 22, 11, 8, 0, 25, 4, 24, 8, 21, 0, 15, 4, 13, 8, 0, 22, 17, 25, 4, 20, 7, 21, 0, 22, 11, 8, 0, 18, 8, 5, 5, 14]\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = np.random.randint(0, len(dataX_seq)-1)\n",
    "pattern = dataX_seq[start]\n",
    "print(start)\n",
    "print(pattern)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ergd, io this shoughts wouh pomkuse willslss ia me wou, iy s"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(60):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
