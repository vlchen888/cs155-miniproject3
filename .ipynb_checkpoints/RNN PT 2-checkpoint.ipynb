{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from Utility import Utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 layer LST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "util = Utility()\n",
    "sonnets = util.get_shakespeare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnetString = []\n",
    "for i in range(len(sonnets)):\n",
    "    sA = sonnets[i+1]\n",
    "    sonnetString.append(\"\")\n",
    "    for k in sA:\n",
    "        for j in k:\n",
    "            sonnetString[-1] += j + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating entire sonnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "dataX = []\n",
    "dataY = []\n",
    "for iter in range(len(sonnetString)):\n",
    "    raw_text = sonnetString[iter]\n",
    "    chars = sorted(list(set(raw_text)))\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "    n_chars = len(raw_text)\n",
    "    for i in range(0, n_chars - seq_length, 5):\n",
    "        seq_in = raw_text[i:i + seq_length]\n",
    "        seq_out = raw_text[i + seq_length]\n",
    "        dataX.append([char_to_int[char] for char in seq_in])\n",
    "        dataY.append(char_to_int[seq_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numpy.reshape(dataX, (len(dataX), seq_length, 1))\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(150, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17400/17409 [============================>.] - ETA: 0s - loss: 2.9714\n",
      "Epoch 00001: loss improved from inf to 2.97109, saving model to weights-improvement-01-2.9711.hdf5\n",
      "17409/17409 [==============================] - 32s 2ms/step - loss: 2.9711\n",
      "Epoch 2/10\n",
      "17400/17409 [============================>.] - ETA: 0s - loss: 2.8821\n",
      "Epoch 00002: loss improved from 2.97109 to 2.88220, saving model to weights-improvement-02-2.8822.hdf5\n",
      "17409/17409 [==============================] - 27s 2ms/step - loss: 2.8822\n",
      "Epoch 3/10\n",
      "17400/17409 [============================>.] - ETA: 0s - loss: 2.8427\n",
      "Epoch 00003: loss improved from 2.88220 to 2.84248, saving model to weights-improvement-03-2.8425.hdf5\n",
      "17409/17409 [==============================] - 27s 2ms/step - loss: 2.8425\n",
      "Epoch 4/10\n",
      "17400/17409 [============================>.] - ETA: 0s - loss: 2.8047\n",
      "Epoch 00004: loss improved from 2.84248 to 2.80468, saving model to weights-improvement-04-2.8047.hdf5\n",
      "17409/17409 [==============================] - 29s 2ms/step - loss: 2.8047\n",
      "Epoch 5/10\n",
      "17400/17409 [============================>.] - ETA: 0s - loss: 2.7732\n",
      "Epoch 00005: loss improved from 2.80468 to 2.77312, saving model to weights-improvement-05-2.7731.hdf5\n",
      "17409/17409 [==============================] - 29s 2ms/step - loss: 2.7731\n",
      "Epoch 6/10\n",
      "17400/17409 [============================>.] - ETA: 0s - loss: 2.7409\n",
      "Epoch 00006: loss improved from 2.77312 to 2.74100, saving model to weights-improvement-06-2.7410.hdf5\n",
      "17409/17409 [==============================] - 27s 2ms/step - loss: 2.7410\n",
      "Epoch 7/10\n",
      "17400/17409 [============================>.] - ETA: 0s - loss: 2.7114- ETA\n",
      "Epoch 00007: loss improved from 2.74100 to 2.71144, saving model to weights-improvement-07-2.7114.hdf5\n",
      "17409/17409 [==============================] - 30s 2ms/step - loss: 2.7114\n",
      "Epoch 8/10\n",
      "17400/17409 [============================>.] - ETA: 0s - loss: 2.6816\n",
      "Epoch 00008: loss improved from 2.71144 to 2.68147, saving model to weights-improvement-08-2.6815.hdf5\n",
      "17409/17409 [==============================] - 28s 2ms/step - loss: 2.6815\n",
      "Epoch 9/10\n",
      "17400/17409 [============================>.] - ETA: 0s - loss: 2.6525\n",
      "Epoch 00009: loss improved from 2.68147 to 2.65252, saving model to weights-improvement-09-2.6525.hdf5\n",
      "17409/17409 [==============================] - 28s 2ms/step - loss: 2.6525\n",
      "Epoch 10/10\n",
      "17400/17409 [============================>.] - ETA: 0s - loss: 2.6244\n",
      "Epoch 00010: loss improved from 2.65252 to 2.62436, saving model to weights-improvement-10-2.6244.hdf5\n",
      "17409/17409 [==============================] - 26s 1ms/step - loss: 2.6244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x181884c6a0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(X, y, epochs=10, batch_size=50, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" - shmd co h nov eoqshew -f-hnrs boneotnc \"\n",
      " sg sgd shdd shdd shd shdd shd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd rgd rndd sgd rnnd r\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
